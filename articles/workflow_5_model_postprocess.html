<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en-GB">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>IASDT modelling workflow — 5. Model post-processing • IASDT.R</title>
<script src="../lightswitch.js"></script><script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet">
<link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet">
<script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="IASDT modelling workflow — 5. Model post-processing">
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top " aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">IASDT.R</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="Released version">0.1.09</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item"><a class="nav-link" href="../reference/index.html"><span class="fa fa-file-code-o"></span> Functions</a></li>
<li class="active nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-modelling-workflow" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true"><span class="fa fas fa-book"></span> Modelling workflow</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-modelling-workflow">
<li><a class="dropdown-item" href="../articles/workflow_1_overview.html">Overview</a></li>
    <li><a class="dropdown-item" href="../articles/workflow_2_abiotic_data.html">Processing abiotic data</a></li>
    <li><a class="dropdown-item" href="../articles/workflow_3_biotic_data.html">Processing biotic data</a></li>
    <li><a class="dropdown-item" href="../articles/workflow_4_model_fitting.html">Model fitting</a></li>
    <li><a class="dropdown-item" href="../articles/workflow_5_model_postprocess.html">Model post-processing</a></li>
  </ul>
</li>
      </ul>
<ul class="navbar-nav">
<li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json">
</form></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/BioDT/IASDT.R/" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
<li class="nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-lightswitch" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true" aria-label="Light switch"><span class="fa fa-sun"></span></button>
  <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="dropdown-lightswitch">
<li><button class="dropdown-item" data-bs-theme-value="light"><span class="fa fa-sun"></span> Light</button></li>
    <li><button class="dropdown-item" data-bs-theme-value="dark"><span class="fa fa-moon"></span> Dark</button></li>
    <li><button class="dropdown-item" data-bs-theme-value="auto"><span class="fa fa-adjust"></span> Auto</button></li>
  </ul>
</li>
      </ul>
</div>


  </div>
</nav><div class="container template-article">



<script src="workflow_5_model_postprocess_files/kePrint-0.0.1/kePrint.js"></script><link href="workflow_5_model_postprocess_files/lightable-0.0.1/lightable.css" rel="stylesheet">
<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">

      <h1>IASDT modelling workflow — 5. Model post-processing</h1>
            
      
      <small class="dont-index">Source: <a href="https://github.com/BioDT/IASDT.R/blob/main/vignettes/workflow_5_model_postprocess.Rmd" class="external-link"><code>vignettes/workflow_5_model_postprocess.Rmd</code></a></small>
      <div class="d-none name"><code>workflow_5_model_postprocess.Rmd</code></div>
    </div>

    
    
<script>
function toggleScript(id) {
  var content = document.getElementById(id);
  if (content.style.display === "none") {
    content.style.display = "block";
  } else {
    content.style.display = "none";
  }
}
</script><style>
/* Styles for the container div that holds the code block */
.ShortBlock {
  width: calc(100% - 40px);    /* Sets the width to 100% of the parent minus 40px to account for the left margin, ensuring it fits within the parent container */
  max-height: 400px;           /* Limits the maximum height to 400px; if content exceeds this, a vertical scrollbar will appear due to overflow-y */
  overflow-y: auto;            /* Enables a vertical scrollbar when content height exceeds max-height (400px), hides it when not needed */
  overflow-x: auto;            /* Enables a horizontal scrollbar when content width exceeds the div's width, hides it when not needed */
  margin-left: 40px;           /* Shifts the entire div (box and scrollbar) 40px to the right from the left edge of its parent, creating indentation */
  color: red;                  /* Sets the text color inside the div to red, applied to the <pre><code> content */
  display: block;              /* Ensures the div behaves as a block-level element, taking full width and stacking vertically */
  box-sizing: border-box;      /* Includes padding and border in the width calculation, preventing overflow beyond the calculated width */
  background-color: #f0f0f0;   /* Adds a light gray background for debugging, visually highlighting the div's area to check indentation */
  position: relative;          /* Sets the div's positioning context to relative, allowing absolute positioning of pseudo-elements (like ::before) within it */
  padding: 10px;               /* Adds 10px padding on all sides (top, right, bottom, left) for internal spacing between the div's edges and content */
}

/* Styles for the <pre> element inside .ShortBlock, which contains the code */
.ShortBlock pre {
  white-space: pre;            /* Preserves whitespace and prevents text wrapping, ensuring long lines extend horizontally as written */
  margin: 0;                   /* Removes default margins of the <pre> element to align it flush with the div's padded edges */
  width: max-content;          /* Sets the width to the natural width of the content (e.g., the longest line), enabling horizontal overflow if wider than the div */
  overflow: auto;              /* Adds scroll bars to the <pre> if its content overflows (though typically overridden by .ShortBlock's overflow-x/y) */
}

/* Customizes the appearance of the horizontal scrollbar for WebKit browsers (e.g., Chrome, Safari) */
.ShortBlock::-webkit-scrollbar {
  height: 10px;                /* Sets the height of the horizontal scrollbar to 10px, making it visible and sized consistently */
}

/* Creates a pseudo-element to simulate a top horizontal scrollbar area */
.ShortBlock::before {
  content: "";                 /* Defines an empty content for the pseudo-element, required to render it */
  display: block;              /* Makes the pseudo-element a block-level element, taking full width and stacking vertically */
  height: 10px;                /* Sets the height to 10px, matching the scrollbar size, creating a scrollable area at the top */
  width: 100%;                 /* Sets the width to 100% of the .ShortBlock div, aligning with its content area */
  position: absolute;          /* Positions the pseudo-element absolutely within the .ShortBlock (due to position: relative on parent) */
  top: 0;                      /* Aligns the pseudo-element to the top edge of the .ShortBlock div */
  left: 0;                     /* Aligns the pseudo-element to the left edge of the .ShortBlock div, starting at the padded edge */
  overflow-x: auto;            /* Enables horizontal scrolling for this pseudo-element, attempting to mirror the content's overflow (experimental) */
}

/* Styles for the button that toggles the collapsible code block */
.ShortBlockButton {
  color: red;                  /* Sets the button text color to red, matching the code block text */
  padding-left: 40px;          /* Adds 40px padding on the left, aligning the button text visually with the indented code block */
  border: none;                /* Removes the default border from the button for a clean look */
  background: none;            /* Removes the default background, making it transparent and minimal */
  cursor: pointer;             /* Changes the cursor to a pointer on hover, indicating the button is clickable */
}

ff {
  background-color: #def5ff;
  color: black;
  font-style: italic;
}

cc {
  background-color: #f0f7eb;
  color: black;
  font-style: italic;
}

.ll:visited {
  color: blue !important;
  text-decoration: none !important;
}

.ll:hover {
  text-decoration: underline !important;
  background-color: #d3f2aa !important;
  color: darkblue !important;
}

.ll:link, .ll:active {
  color: blue !important;
  text-decoration: none !important;
}

tab:before {
  content: "\00a0\00a0\00a0\00a0";
}

tab0:after {
  content: "\00a0\00a0";
}

table{
    width: 100% !important;
    margin-left: 50px !important;
}

table, th, td {
  padding: 1.8px !important;
  line-height: 1.3 !important;
}

.hr1 {
    width: 90%;
    margin-left: auto;
    margin-right: auto;
    border-top: 6px groove blue;
    margin: 30px auto;
    height: 4px;
    background-color: blue;
}

.hr2 {
    width: 50%;
    margin-left: auto;
    margin-right: auto;
    border-top: 6px groove orange;
    margin: 25px auto;
    height: 2px;
    background-color: orange;
}

br {
  display: block;
  margin: 4px 0;
}
</style>
<p><br></p>
<p>Post-processing of fitted models in the <code>IASDT</code> workflow
involves multiple steps, utilising both CPU and GPU computations to
optimize performance and manage memory constraints effectively.</p>
<p><br></p>
<div class="section level2">
<h2 id="step-1-cpu">Step 1: CPU<a class="anchor" aria-label="anchor" href="#step-1-cpu"></a>
</h2>
<p>The <strong><code><a href="../reference/Mod_postprocessing.html">mod_postprocess_1_CPU()</a></code></strong> function
begins the post-processing phase for each habitat type by automating the
following tasks:</p>
<table class="table table table-condensed table-hover" style="font-size: 16px; margin-left: auto; margin-right: auto;"><tbody>
<tr>
<td style="text-align:left;padding-left: 4em;white-space: nowrap;" indentlevel="1">
<cc><code><a href="../reference/Mod_SLURM.html">mod_SLURM_refit()</a></code></cc><tab0></tab0>
</td>
<td style="text-align:left;">
checks for unsuccessful model fits.
</td>
</tr>
<tr>
<td style="text-align:left;padding-left: 4em;white-space: nowrap;" indentlevel="1">
<cc><code><a href="../reference/Mod_Merge_Chains.html">mod_merge_chains()</a></code></cc><tab0></tab0>
</td>
<td style="text-align:left;">
merges MCMC chains and saves the fitted model and coda objects to
<code>.qs2</code> or <code>.RData</code> files.
</td>
</tr>
<tr>
<td style="text-align:left;padding-left: 4em;white-space: nowrap;" indentlevel="1">
<cc><code><a href="../reference/Convergence_Plot_All.html">convergence_plot_all()</a></code></cc><tab0></tab0>
</td>
<td style="text-align:left;">
visualises the convergence of <code>rho</code>, <code>alpha</code>,
<code>omega</code>, and <code>beta</code> parameters across all model
variants. This function is particularly useful for comparing convergence
across models with different thinning values, with and without
phylogenetic relationships, or varying GPP knot distances. It is
unnecessary when only a single model variant is considered.
</td>
</tr>
<tr>
<td style="text-align:left;padding-left: 4em;white-space: nowrap;" indentlevel="1">
<cc><code><a href="../reference/Convergence_plots.html">convergence_plot()</a></code></cc><tab0></tab0>
</td>
<td style="text-align:left;">
displays the convergence of <code>rho</code>, <code>alpha</code>,
<code>omega</code>, and <code>beta</code> parameters for a selected
model, providing a more detailed view compared to
<code><a href="../reference/Convergence_Plot_All.html">convergence_plot_all()</a></code>.
</td>
</tr>
<tr>
<td style="text-align:left;padding-left: 4em;white-space: nowrap;" indentlevel="1">
<cc><code><a href="../reference/plot_gelman.html">plot_gelman()</a></code></cc><tab0></tab0>
</td>
<td style="text-align:left;">
visualises the Gelman-Rubin-Brooks diagnostics for the selected model.
</td>
</tr>
<tr>
<td style="text-align:left;padding-left: 4em;white-space: nowrap;" indentlevel="1">
<cc><code><a href="../reference/Mod_Summary.html">mod_summary()</a></code></cc><tab0></tab0>
</td>
<td style="text-align:left;">
extracts and saves a summary of the model.
</td>
</tr>
<tr>
<td style="text-align:left;padding-left: 4em;white-space: nowrap;" indentlevel="1">
<cc><code><a href="../reference/Parameter_Heatmap.html">mod_heatmap_beta()</a></code></cc><tab0></tab0>
</td>
<td style="text-align:left;">
generates heatmaps of the <code>beta</code> parameters.
</td>
</tr>
<tr>
<td style="text-align:left;padding-left: 4em;white-space: nowrap;" indentlevel="1">
<cc><code><a href="../reference/Parameter_Heatmap.html">mod_heatmap_omega()</a></code></cc><tab0></tab0>
</td>
<td style="text-align:left;">
generates heatmaps of the <code>omega</code> parameter, which represents
residual species associations.
</td>
</tr>
<tr>
<td style="text-align:left;padding-left: 4em;white-space: nowrap;" indentlevel="1">
<cc><code><a href="../reference/Mod_CV_Fit.html">mod_CV_fit()</a></code></cc><tab0></tab0>
</td>
<td style="text-align:left;">
prepares the necessary data for fitting cross-validated models.
<ul>
<li>
output files are saved in the <code>Model_Fitting_CV</code>
subdirectory.
</li>
<li>
the type of cross-validation strategy is controlled by the
<code>CV_name</code> argument, which defaults to both
<code>CV_Dist</code> and <code>CV_Large</code>.
</li>
<li>
unfitted model objects are saved in the <code>Model_Init</code>
subdirectory.
</li>
<li>
commands for model fitting are saved as text files, with a separate file
for each cross-validation strategy (e.g.,
<code>Commands2Fit_CV_Dist.txt</code>,
<code>Commands2Fit_CV_Large.txt</code>).
</li>
<li>
model fitting commands are submitted as batch jobs using SLURM scripts,
with a separate script for each strategy (e.g.,
<code>CV_Bash_Fit_Dist.slurm</code>,
<code>CV_Bash_Fit_Large.slurm</code>).
</li>
</ul>
</td>
</tr>
</tbody></table>
<br><hr class="hr2">
<p><br></p>
<div class="section level3">
<h3 id="computationally-intensive-tasks-offloaded-to-gpu">Computationally intensive tasks offloaded to GPU<a class="anchor" aria-label="anchor" href="#computationally-intensive-tasks-offloaded-to-gpu"></a>
</h3>
<p>Previous attempts to prepare response curve data, predict at new
sites, and compute variance partitioning using R on CPUs (such as the
UFZ Windows server and LUMI HPC) were limited by memory constraints. As
a result, these tasks are now offloaded to GPU-based computations using
<code>Python</code> and <code>TensorFlow</code>. The
<code><a href="../reference/Mod_postprocessing.html">mod_postprocess_1_CPU()</a></code> function calls the following
sub-functions to generate the necessary commands for GPU execution:</p>
<table class="table table table-condensed table-hover" style="font-size: 16px; margin-left: auto; margin-right: auto;"><tbody>
<tr>
<td style="text-align:left;padding-left: 4em;white-space: nowrap;" indentlevel="1">
<cc><code><a href="../reference/Response_curves.html">resp_curv_prepare_data()</a></code></cc><tab0></tab0>
</td>
<td style="text-align:left;">
prepares data for predicting latent factors for response curves
</td>
</tr>
<tr>
<td style="text-align:left;padding-left: 4em;white-space: nowrap;" indentlevel="1">
<cc><code><a href="../reference/Predict_Maps.html">predict_maps()</a></code></cc><tab0></tab0>
</td>
<td style="text-align:left;">
prepares data for predicting latent factors at new sampling units
</td>
</tr>
<tr>
<td style="text-align:left;padding-left: 4em;white-space: nowrap;" indentlevel="1">
<cc><code><a href="../reference/Variance_partitioning.html">variance_partitioning_compute()</a></code></cc><tab0></tab0>
</td>
<td style="text-align:left;">
prepares data for computing variance partitioning
</td>
</tr>
</tbody></table>
<br><hr class="hr2">
<p><br></p>
</div>
<div class="section level3">
<h3 id="preparing-commands-for-gpu-computations">Preparing commands for GPU computations<a class="anchor" aria-label="anchor" href="#preparing-commands-for-gpu-computations"></a>
</h3>
<blockquote>
<p><u><i>Predicting latent factors:</i></u></p>
</blockquote>
<ul>
<li>Predictions of latent factors for response curves and new sampling
units are performed using a <code>TensorFlow</code> script located at
<a href="https://github.com/BioDT/IASDT.R/blob/main/inst/crossprod_solve.py" target="_blank" class="external-link ll">inst/crossprod_solve.py</a>.</li>
<li>For these tasks, the corresponding R functions export multiple
<code>.qs2</code> and <code>.feather</code> data files to the
<ff>TEMP_Pred</ff> subdirectory, which are essential for GPU
computations. Additionally, they generate execution commands saved as
<ff>LF_RC_Commands_<em>.txt</em></ff> (for response curves) and
<ff>LF_NewSites_Commands_.txt</ff> (for new sites).</li>
</ul>
<button onclick="toggleScript('scriptContentNS1')" class="ShortBlockButton">
»» Example LF_RC_Commands.txt file
</button>
<div id="scriptContentNS1" class="ShortBlock" style="display: none;">
<pre><code class="bash">python3 crossprod_solve.py --s1 RC_c_s1.feather --s2 RC_c_s2.feather --post_eta RC_c_postEta_ch001.feather --path_out RC_c_etaPred_ch001.feather --denom 1200000 --chunk_size 1000 --threshold_mb 2000 --solve_chunk_size 50 --verbose  &gt;&gt; RC_c_etaPred_ch001.log 2&gt;&amp;1
python3 crossprod_solve.py --s1 RC_c_s1.feather --s2 RC_c_s2.feather --post_eta RC_c_postEta_ch002.feather --path_out RC_c_etaPred_ch002.feather --denom 1188081 --chunk_size 1000 --threshold_mb 2000 --solve_chunk_size 50 --verbose  &gt;&gt; RC_c_etaPred_ch002.log 2&gt;&amp;1
python3 crossprod_solve.py --s1 RC_c_s1.feather --s2 RC_c_s2.feather --post_eta RC_c_postEta_ch003.feather --path_out RC_c_etaPred_ch003.feather --denom 1176162 --chunk_size 1000 --threshold_mb 2000 --solve_chunk_size 50 --verbose  &gt;&gt; RC_c_etaPred_ch003.log 2&gt;&amp;1
python3 crossprod_solve.py --s1 RC_c_s1.feather --s2 RC_c_s2.feather --post_eta RC_c_postEta_ch004.feather --path_out RC_c_etaPred_ch004.feather --denom 1164242 --chunk_size 1000 --threshold_mb 2000 --solve_chunk_size 50 --verbose  &gt;&gt; RC_c_etaPred_ch004.log 2&gt;&amp;1
python3 crossprod_solve.py --s1 RC_c_s1.feather --s2 RC_c_s2.feather --post_eta RC_c_postEta_ch005.feather --path_out RC_c_etaPred_ch005.feather --denom 1200000 --chunk_size 1000 --threshold_mb 2000 --solve_chunk_size 50 --verbose  &gt;&gt; RC_c_etaPred_ch005.log 2&gt;&amp;1
python3 crossprod_solve.py --s1 RC_c_s1.feather --s2 RC_c_s2.feather --post_eta RC_c_postEta_ch006.feather --path_out RC_c_etaPred_ch006.feather --denom 413333 --chunk_size 1000 --threshold_mb 2000 --solve_chunk_size 50 --verbose  &gt;&gt; RC_c_etaPred_ch006.log 2&gt;&amp;1
python3 crossprod_solve.py --s1 RC_c_s1.feather --s2 RC_c_s2.feather --post_eta RC_c_postEta_ch007.feather --path_out RC_c_etaPred_ch007.feather --denom 1188081 --chunk_size 1000 --threshold_mb 2000 --solve_chunk_size 50 --verbose  &gt;&gt; RC_c_etaPred_ch007.log 2&gt;&amp;1
python3 crossprod_solve.py --s1 RC_c_s1.feather --s2 RC_c_s2.feather --post_eta RC_c_postEta_ch008.feather --path_out RC_c_etaPred_ch008.feather --denom 425253 --chunk_size 1000 --threshold_mb 2000 --solve_chunk_size 50 --verbose  &gt;&gt; RC_c_etaPred_ch008.log 2&gt;&amp;1
python3 crossprod_solve.py --s1 RC_c_s1.feather --s2 RC_c_s2.feather --post_eta RC_c_postEta_ch009.feather --path_out RC_c_etaPred_ch009.feather --denom 1176162 --chunk_size 1000 --threshold_mb 2000 --solve_chunk_size 50 --verbose  &gt;&gt; RC_c_etaPred_ch009.log 2&gt;&amp;1
python3 crossprod_solve.py --s1 RC_c_s1.feather --s2 RC_c_s2.feather --post_eta RC_c_postEta_ch010.feather --path_out RC_c_etaPred_ch010.feather --denom 437172 --chunk_size 1000 --threshold_mb 2000 --solve_chunk_size 50 --verbose  &gt;&gt; RC_c_etaPred_ch010.log 2&gt;&amp;1
python3 crossprod_solve.py --s1 RC_c_s1.feather --s2 RC_c_s2.feather --post_eta RC_c_postEta_ch011.feather --path_out RC_c_etaPred_ch011.feather --denom 1200000 --chunk_size 1000 --threshold_mb 2000 --solve_chunk_size 50 --verbose  &gt;&gt; RC_c_etaPred_ch011.log 2&gt;&amp;1
python3 crossprod_solve.py --s1 RC_c_s1.feather --s2 RC_c_s2.feather --post_eta RC_c_postEta_ch012.feather --path_out RC_c_etaPred_ch012.feather --denom 401414 --chunk_size 1000 --threshold_mb 2000 --solve_chunk_size 50 --verbose  &gt;&gt; RC_c_etaPred_ch012.log 2&gt;&amp;1
python3 crossprod_solve.py --s1 RC_c_s1.feather --s2 RC_c_s2.feather --post_eta RC_c_postEta_ch013.feather --path_out RC_c_etaPred_ch013.feather --denom 1164242 --chunk_size 1000 --threshold_mb 2000 --solve_chunk_size 50 --verbose  &gt;&gt; RC_c_etaPred_ch013.log 2&gt;&amp;1
python3 crossprod_solve.py --s1 RC_c_s1.feather --s2 RC_c_s2.feather --post_eta RC_c_postEta_ch014.feather --path_out RC_c_etaPred_ch014.feather --denom 449091 --chunk_size 1000 --threshold_mb 2000 --solve_chunk_size 50 --verbose  &gt;&gt; RC_c_etaPred_ch014.log 2&gt;&amp;1
python3 crossprod_solve.py --s1 RC_c_s1.feather --s2 RC_c_s2.feather --post_eta RC_c_postEta_ch015.feather --path_out RC_c_etaPred_ch015.feather --denom 1152323 --chunk_size 1000 --threshold_mb 2000 --solve_chunk_size 50 --verbose  &gt;&gt; RC_c_etaPred_ch015.log 2&gt;&amp;1</code></pre>
</div>
<p><br></p>
<button onclick="toggleScript('scriptContentNS2')" class="ShortBlockButton">
»» Example LF_NewSites_Commands.txt file
</button>
<div id="scriptContentNS2" class="ShortBlock" style="display: none;">
<pre><code class="bash">python3 crossprod_solve.py --s1 LF_3_Test_s1.feather --s2 LF_3_Test_s2.feather --post_eta LF_3_Test_postEta_ch001.feather --path_out LF_3_Test_etaPred_ch001.feather --denom 225758 --chunk_size 1000 --threshold_mb 2000 --solve_chunk_size 50 --verbose  &gt;&gt; LF_3_Test_etaPred_ch001.log 2&gt;&amp;1
python3 crossprod_solve.py --s1 LF_3_Test_s1.feather --s2 LF_3_Test_s2.feather --post_eta LF_3_Test_postEta_ch002.feather --path_out LF_3_Test_etaPred_ch002.feather --denom 211111 --chunk_size 1000 --threshold_mb 2000 --solve_chunk_size 50 --verbose  &gt;&gt; LF_3_Test_etaPred_ch002.log 2&gt;&amp;1
python3 crossprod_solve.py --s1 LF_3_Test_s1.feather --s2 LF_3_Test_s2.feather --post_eta LF_3_Test_postEta_ch003.feather --path_out LF_3_Test_etaPred_ch003.feather --denom 240404 --chunk_size 1000 --threshold_mb 2000 --solve_chunk_size 50 --verbose  &gt;&gt; LF_3_Test_etaPred_ch003.log 2&gt;&amp;1
python3 crossprod_solve.py --s1 LF_3_Test_s1.feather --s2 LF_3_Test_s2.feather --post_eta LF_3_Test_postEta_ch004.feather --path_out LF_3_Test_etaPred_ch004.feather --denom 196465 --chunk_size 1000 --threshold_mb 2000 --solve_chunk_size 50 --verbose  &gt;&gt; LF_3_Test_etaPred_ch004.log 2&gt;&amp;1
python3 crossprod_solve.py --s1 LF_3_Test_s1.feather --s2 LF_3_Test_s2.feather --post_eta LF_3_Test_postEta_ch005.feather --path_out LF_3_Test_etaPred_ch005.feather --denom 196465 --chunk_size 1000 --threshold_mb 2000 --solve_chunk_size 50 --verbose  &gt;&gt; LF_3_Test_etaPred_ch005.log 2&gt;&amp;1
python3 crossprod_solve.py --s1 LF_3_Test_s1.feather --s2 LF_3_Test_s2.feather --post_eta LF_3_Test_postEta_ch006.feather --path_out LF_3_Test_etaPred_ch006.feather --denom 211111 --chunk_size 1000 --threshold_mb 2000 --solve_chunk_size 50 --verbose  &gt;&gt; LF_3_Test_etaPred_ch006.log 2&gt;&amp;1
python3 crossprod_solve.py --s1 LF_3_Test_s1.feather --s2 LF_3_Test_s2.feather --post_eta LF_3_Test_postEta_ch007.feather --path_out LF_3_Test_etaPred_ch007.feather --denom 225758 --chunk_size 1000 --threshold_mb 2000 --solve_chunk_size 50 --verbose  &gt;&gt; LF_3_Test_etaPred_ch007.log 2&gt;&amp;1
python3 crossprod_solve.py --s1 LF_3_Test_s1.feather --s2 LF_3_Test_s2.feather --post_eta LF_3_Test_postEta_ch008.feather --path_out LF_3_Test_etaPred_ch008.feather --denom 181818 --chunk_size 1000 --threshold_mb 2000 --solve_chunk_size 50 --verbose  &gt;&gt; LF_3_Test_etaPred_ch008.log 2&gt;&amp;1
python3 crossprod_solve.py --s1 LF_3_Test_s1.feather --s2 LF_3_Test_s2.feather --post_eta LF_3_Test_postEta_ch009.feather --path_out LF_3_Test_etaPred_ch009.feather --denom 255051 --chunk_size 1000 --threshold_mb 2000 --solve_chunk_size 50 --verbose  &gt;&gt; LF_3_Test_etaPred_ch009.log 2&gt;&amp;1
python3 crossprod_solve.py --s1 LF_3_Test_s1.feather --s2 LF_3_Test_s2.feather --post_eta LF_3_Test_postEta_ch010.feather --path_out LF_3_Test_etaPred_ch010.feather --denom 240404 --chunk_size 1000 --threshold_mb 2000 --solve_chunk_size 50 --verbose  &gt;&gt; LF_3_Test_etaPred_ch010.log 2&gt;&amp;1
python3 crossprod_solve.py --s1 LF_3_Test_s1.feather --s2 LF_3_Test_s2.feather --post_eta LF_3_Test_postEta_ch011.feather --path_out LF_3_Test_etaPred_ch011.feather --denom 167172 --chunk_size 1000 --threshold_mb 2000 --solve_chunk_size 50 --verbose  &gt;&gt; LF_3_Test_etaPred_ch011.log 2&gt;&amp;1
python3 crossprod_solve.py --s1 LF_3_Test_s1.feather --s2 LF_3_Test_s2.feather --post_eta LF_3_Test_postEta_ch012.feather --path_out LF_3_Test_etaPred_ch012.feather --denom 269697 --chunk_size 1000 --threshold_mb 2000 --solve_chunk_size 50 --verbose  &gt;&gt; LF_3_Test_etaPred_ch012.log 2&gt;&amp;1
python3 crossprod_solve.py --s1 LF_3_Test_s1.feather --s2 LF_3_Test_s2.feather --post_eta LF_3_Test_postEta_ch013.feather --path_out LF_3_Test_etaPred_ch013.feather --denom 255051 --chunk_size 1000 --threshold_mb 2000 --solve_chunk_size 50 --verbose  &gt;&gt; LF_3_Test_etaPred_ch013.log 2&gt;&amp;1
python3 crossprod_solve.py --s1 LF_3_Test_s1.feather --s2 LF_3_Test_s2.feather --post_eta LF_3_Test_postEta_ch014.feather --path_out LF_3_Test_etaPred_ch014.feather --denom 269697 --chunk_size 1000 --threshold_mb 2000 --solve_chunk_size 50 --verbose  &gt;&gt; LF_3_Test_etaPred_ch014.log 2&gt;&amp;1
python3 crossprod_solve.py --s1 LF_3_Test_s1.feather --s2 LF_3_Test_s2.feather --post_eta LF_3_Test_postEta_ch015.feather --path_out LF_3_Test_etaPred_ch015.feather --denom 181818 --chunk_size 1000 --threshold_mb 2000 --solve_chunk_size 50 --verbose  &gt;&gt; LF_3_Test_etaPred_ch015.log 2&gt;&amp;1</code></pre>
</div>
<p><br><br></p>
<ul>
<li>Response curves
<ul>
<li>
<code><a href="../reference/Response_curves.html">resp_curv_prepare_data()</a></code> extends the functionality of
<code><a href="https://rdrr.io/pkg/Hmsc/man/constructGradient.html" class="external-link">Hmsc::constructGradient()</a></code> and
<code><a href="https://rdrr.io/pkg/Hmsc/man/plotGradient.html" class="external-link">Hmsc::plotGradient()</a></code> by enabling the preparation of
response curve data on GPUs when
<code>LF_commands_only = TRUE</code>.</li>
<li>For predictions at mean coordinates (as specified by the
<code>coordinates</code> argument in
<code><a href="https://rdrr.io/pkg/Hmsc/man/constructGradient.html" class="external-link">Hmsc::constructGradient()</a></code>), latent factor predictions —
which are typically memory-intensive when using
<code><a href="https://rdrr.io/pkg/Hmsc/man/predictLatentFactor.html" class="external-link">Hmsc::predictLatentFactor()</a></code> — are computed on GPUs.</li>
</ul>
</li>
<li>Predicting at new sites
<ul>
<li>
<code><a href="../reference/Predict_Maps.html">predict_maps()</a></code> sets up GPU computations for predictions
at new sites when both <code>LF_only = TRUE</code> and
<code>LF_commands_only = TRUE</code>.</li>
</ul>
</li>
</ul>
<p><br><br></p>
<blockquote>
<p><u><i>Computing variance partitioning:</i></u></p>
</blockquote>
<ul>
<li>Variance partitioning computations are performed on GPUs using
<code>TensorFlow</code> scripts located at
<a href="https://github.com/BioDT/IASDT.R/blob/main/inst/VP_geta.py" target="_blank" class="external-link ll">inst/VP_geta.py</a>,
<a href="https://github.com/BioDT/IASDT.R/blob/main/inst/VP_getf.py" target="_blank" class="external-link ll">inst/VP_getf.py</a>,
and
<a href="https://github.com/BioDT/IASDT.R/blob/main/inst/VP_gemu.py" target="_blank" class="external-link ll">inst/VP_gemu.py</a>.
These scripts implement functionality derived from
<code><a href="https://rdrr.io/pkg/Hmsc/man/computeVariancePartitioning.html" class="external-link">Hmsc::computeVariancePartitioning()</a></code>, specifically the
internal functions <code>geta</code>, <code>getf</code>, and
<code>gemu</code>.</li>
<li>The <code><a href="../reference/Variance_partitioning.html">variance_partitioning_compute()</a></code> function exports
the necessary files to the <ff>TEMP_VP</ff> subdirectory, including
numerous <code>.qs2</code> and <code>.feather</code> files. It also
generates execution commands saved as <ff>VP_A_Command.txt</ff>,
<ff>VP_F_Command.txt</ff>, and <ff>VP_mu_Command.txt</ff>.</li>
</ul>
<p><br><br></p>
</div>
<div class="section level3">
<h3 id="combining-commands-for-gpu-computations">Combining commands for GPU computations<a class="anchor" aria-label="anchor" href="#combining-commands-for-gpu-computations"></a>
</h3>
<p>Once <code><a href="../reference/Mod_postprocessing.html">mod_postprocess_1_CPU()</a></code> has been executed for all
habitat types, the <strong><code><a href="../reference/Mod_postprocessing.html">mod_prepare_TF()</a></code></strong>
function consolidates the batch scripts for GPU computations across all
habitat types:</p>
<ul>
<li>It aggregates the script files that contain commands for response
curves and latent factor predictions, splitting them into multiple
scripts (<ff>TF_Chunk_*.txt</ff>) for batch processing. Additionally, it
generates a SLURM script (<ff>LF_SLURM.slurm</ff>) for executing the
latent factor predictions.</li>
</ul>
<button onclick="toggleScript('scriptContentNS3')" class="ShortBlockButton">
»» Example TF_Chunk_*.txt file
</button>
<div id="scriptContentNS3" class="ShortBlock" style="display: none;">
<pre><code class="bash">#!/bin/bash

# Load TensorFlow module and configure environment
ml use /appl/local/csc/modulefiles
ml tensorflow
export TF_CPP_MIN_LOG_LEVEL=3
export TF_ENABLE_ONEDNN_OPTS=0

# Verify GPU availability
python3 -c "import tensorflow as tf; print(\"Num GPUs Available:\", len(tf.config.list_physical_devices(\"GPU\")))"

# 20 commands to be executed:
python3 crossprod_solve.py --s1 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_s1.feather' --s2 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_s2.feather' --post_eta 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_postEta_ch001.feather' --path_out 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_etaPred_ch001.feather' --denom 50000 --chunk_size 1000 --threshold_mb 2000 --solve_chunk_size 50 --verbose  &gt;&gt; datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_etaPred_ch001.log 2&gt;&amp;1
python3 crossprod_solve.py --s1 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_s1.feather' --s2 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_s2.feather' --post_eta 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_postEta_ch002.feather' --path_out 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_etaPred_ch002.feather' --denom 1470707 --chunk_size 1000 --threshold_mb 2000 --solve_chunk_size 50 --verbose  &gt;&gt; datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_etaPred_ch002.log 2&gt;&amp;1
python3 crossprod_solve.py --s1 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_s1.feather' --s2 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_s2.feather' --post_eta 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_postEta_ch003.feather' --path_out 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_etaPred_ch003.feather' --denom 1485354 --chunk_size 1000 --threshold_mb 2000 --solve_chunk_size 50 --verbose  &gt;&gt; datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_etaPred_ch003.log 2&gt;&amp;1
python3 crossprod_solve.py --s1 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_s1.feather' --s2 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_s2.feather' --post_eta 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_postEta_ch004.feather' --path_out 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_etaPred_ch004.feather' --denom 1456061 --chunk_size 1000 --threshold_mb 2000 --solve_chunk_size 50 --verbose  &gt;&gt; datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_etaPred_ch004.log 2&gt;&amp;1
python3 crossprod_solve.py --s1 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_s1.feather' --s2 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_s2.feather' --post_eta 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_postEta_ch005.feather' --path_out 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_etaPred_ch005.feather' --denom 1500000 --chunk_size 1000 --threshold_mb 2000 --solve_chunk_size 50 --verbose  &gt;&gt; datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_etaPred_ch005.log 2&gt;&amp;1
python3 crossprod_solve.py --s1 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_s1.feather' --s2 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_s2.feather' --post_eta 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_postEta_ch006.feather' --path_out 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_etaPred_ch006.feather' --denom 1500000 --chunk_size 1000 --threshold_mb 2000 --solve_chunk_size 50 --verbose  &gt;&gt; datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_etaPred_ch006.log 2&gt;&amp;1
python3 crossprod_solve.py --s1 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_s1.feather' --s2 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_s2.feather' --post_eta 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_postEta_ch007.feather' --path_out 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_etaPred_ch007.feather' --denom 1426768 --chunk_size 1000 --threshold_mb 2000 --solve_chunk_size 50 --verbose  &gt;&gt; datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_etaPred_ch007.log 2&gt;&amp;1
python3 crossprod_solve.py --s1 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_s1.feather' --s2 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_s2.feather' --post_eta 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_postEta_ch008.feather' --path_out 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_etaPred_ch008.feather' --denom 1470707 --chunk_size 1000 --threshold_mb 2000 --solve_chunk_size 50 --verbose  &gt;&gt; datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_etaPred_ch008.log 2&gt;&amp;1
python3 crossprod_solve.py --s1 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_s1.feather' --s2 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_s2.feather' --post_eta 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_postEta_ch009.feather' --path_out 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_etaPred_ch009.feather' --denom 1485354 --chunk_size 1000 --threshold_mb 2000 --solve_chunk_size 50 --verbose  &gt;&gt; datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_etaPred_ch009.log 2&gt;&amp;1
python3 crossprod_solve.py --s1 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_s1.feather' --s2 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_s2.feather' --post_eta 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_postEta_ch010.feather' --path_out 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_etaPred_ch010.feather' --denom 1456061 --chunk_size 1000 --threshold_mb 2000 --solve_chunk_size 50 --verbose  &gt;&gt; datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_etaPred_ch010.log 2&gt;&amp;1
python3 crossprod_solve.py --s1 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_s1.feather' --s2 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_s2.feather' --post_eta 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_postEta_ch011.feather' --path_out 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_etaPred_ch011.feather' --denom 1470707 --chunk_size 1000 --threshold_mb 2000 --solve_chunk_size 50 --verbose  &gt;&gt; datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_etaPred_ch011.log 2&gt;&amp;1
python3 crossprod_solve.py --s1 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_s1.feather' --s2 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_s2.feather' --post_eta 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_postEta_ch012.feather' --path_out 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_etaPred_ch012.feather' --denom 1412121 --chunk_size 1000 --threshold_mb 2000 --solve_chunk_size 50 --verbose  &gt;&gt; datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_etaPred_ch012.log 2&gt;&amp;1
python3 crossprod_solve.py --s1 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_s1.feather' --s2 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_s2.feather' --post_eta 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_postEta_ch013.feather' --path_out 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_etaPred_ch013.feather' --denom 1426768 --chunk_size 1000 --threshold_mb 2000 --solve_chunk_size 50 --verbose  &gt;&gt; datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_etaPred_ch013.log 2&gt;&amp;1
python3 crossprod_solve.py --s1 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_s1.feather' --s2 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_s2.feather' --post_eta 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_postEta_ch014.feather' --path_out 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_etaPred_ch014.feather' --denom 1426768 --chunk_size 1000 --threshold_mb 2000 --solve_chunk_size 50 --verbose  &gt;&gt; datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_etaPred_ch014.log 2&gt;&amp;1
python3 crossprod_solve.py --s1 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_s1.feather' --s2 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_s2.feather' --post_eta 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_postEta_ch015.feather' --path_out 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_etaPred_ch015.feather' --denom 1441414 --chunk_size 1000 --threshold_mb 2000 --solve_chunk_size 50 --verbose  &gt;&gt; datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_etaPred_ch015.log 2&gt;&amp;1
python3 crossprod_solve.py --s1 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_s1.feather' --s2 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_s2.feather' --post_eta 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_postEta_ch016.feather' --path_out 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_etaPred_ch016.feather' --denom 1456061 --chunk_size 1000 --threshold_mb 2000 --solve_chunk_size 50 --verbose  &gt;&gt; datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_etaPred_ch016.log 2&gt;&amp;1
python3 crossprod_solve.py --s1 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_s1.feather' --s2 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_s2.feather' --post_eta 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_postEta_ch017.feather' --path_out 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_etaPred_ch017.feather' --denom 1441414 --chunk_size 1000 --threshold_mb 2000 --solve_chunk_size 50 --verbose  &gt;&gt; datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_etaPred_ch017.log 2&gt;&amp;1
python3 crossprod_solve.py --s1 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_s1.feather' --s2 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_s2.feather' --post_eta 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_postEta_ch018.feather' --path_out 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_etaPred_ch018.feather' --denom 1382828 --chunk_size 1000 --threshold_mb 2000 --solve_chunk_size 50 --verbose  &gt;&gt; datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_etaPred_ch018.log 2&gt;&amp;1
python3 crossprod_solve.py --s1 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_s1.feather' --s2 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_s2.feather' --post_eta 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_postEta_ch019.feather' --path_out 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_etaPred_ch019.feather' --denom 1485354 --chunk_size 1000 --threshold_mb 2000 --solve_chunk_size 50 --verbose  &gt;&gt; datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_etaPred_ch019.log 2&gt;&amp;1
python3 crossprod_solve.py --s1 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_s1.feather' --s2 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_s2.feather' --post_eta 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_postEta_ch020.feather' --path_out 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_etaPred_ch020.feather' --denom 1368182 --chunk_size 1000 --threshold_mb 2000 --solve_chunk_size 50 --verbose  &gt;&gt; datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_etaPred_ch020.log 2&gt;&amp;1</code></pre>
</div>
<p><br></p>
<button onclick="toggleScript('scriptContentNS4')" class="ShortBlockButton">
»» Example LF_SLURM.slurm file
</button>
<div id="scriptContentNS4" class="ShortBlock" style="display: none;">
<pre><code class="bash">#!/bin/bash
#SBATCH --job-name=PP_LF
#SBATCH --ntasks=1
#SBATCH --ntasks-per-node=1
#SBATCH --account=project_465001588
#SBATCH --cpus-per-task=1
#SBATCH --gpus-per-node=1
#SBATCH --time=01:00:00
#SBATCH --partition=small-g
#SBATCH --output=datasets/processed/model_fitting/TMP/%x-%A-%a.out
#SBATCH --error=datasets/processed/model_fitting/TMP/%x-%A-%a.out
#SBATCH --array=1-186

# Define directories
OutputDir="datasets/processed/model_fitting/TF_BatchFiles"

# Find all the split files and sort them explicitly
SplitFiles=($(find "$OutputDir" -type f -name "TF_Chunk_*.txt" | sort -V))

# Check if files were found
if [ ${#SplitFiles[@]} -eq 0 ]; then
    echo "Error: No files matching TF_Chunk_*.txt found in $OutputDir"
    exit 1
fi

# Ensure no more than `, NumFiles, ` files are processed
MaxFiles=186
if [ ${#SplitFiles[@]} -gt $MaxFiles ]; then
    SplitFiles=("${SplitFiles[@]:0:$MaxFiles}")
    echo "More than $MaxFiles files found, limiting to the first $MaxFiles files."
fi

# Get the index of the current task based on SLURM_ARRAY_TASK_ID
TaskIndex=$((SLURM_ARRAY_TASK_ID - 1))

# Validate TaskIndex
if [ $TaskIndex -ge ${#SplitFiles[@]} ] || [ $TaskIndex -lt 0 ]; then
    echo "Error: TaskIndex $TaskIndex is out of range. Valid range: 0 to $((${#SplitFiles[@]} - 1))"
    exit 1
fi

# Get the specific split file to process based on the job array task ID
SplitFile="${SplitFiles[$TaskIndex]}"

# Verify the selected split file
if [ -z "$SplitFile" ] || [ ! -f "$SplitFile" ]; then
    echo "Error: File $SplitFile does not exist or is invalid."
    exit 1
fi

# Processing file
echo "Processing file: $SplitFile"

# Run the selected split file
bash "$SplitFile"

echo End of program at `date`</code></pre>
</div>
<p><br></p>
<ul>
<li>It combines the variance partitioning command files into a single
<ff>VP_Commands.txt</ff> file and prepares a SLURM script
(<ff>VP_SLURM.slurm</ff>) for the variance partitioning
computations.</li>
</ul>
<button onclick="toggleScript('scriptContentNS5')" class="ShortBlockButton">
»» Example VP_Commands.txt file
</button>
<div id="scriptContentNS5" class="ShortBlock" style="display: none;">
<pre><code class="bash">python3 VP_gemu.py --tr datasets/processed/model_fitting/Mod_Q_Hab1/TEMP_VP/VP_Tr.feather --gamma datasets/processed/model_fitting/Mod_Q_Hab1/TEMP_VP/VP_Gamma.feather --output datasets/processed/model_fitting/Mod_Q_Hab1/TEMP_VP/VP_Mu.feather --ncores 3 --chunk_size 50 &gt;&gt; datasets/processed/model_fitting/Mod_Q_Hab1/TEMP_VP/VP_Mu.log 2&gt;&amp;1
python3 VP_gemu.py --tr datasets/processed/model_fitting/Mod_Q_Hab2/TEMP_VP/VP_Tr.feather --gamma datasets/processed/model_fitting/Mod_Q_Hab2/TEMP_VP/VP_Gamma.feather --output datasets/processed/model_fitting/Mod_Q_Hab2/TEMP_VP/VP_Mu.feather --ncores 3 --chunk_size 50 &gt;&gt; datasets/processed/model_fitting/Mod_Q_Hab2/TEMP_VP/VP_Mu.log 2&gt;&amp;1
python3 VP_gemu.py --tr datasets/processed/model_fitting/Mod_Q_Hab3/TEMP_VP/VP_Tr.feather --gamma datasets/processed/model_fitting/Mod_Q_Hab3/TEMP_VP/VP_Gamma.feather --output datasets/processed/model_fitting/Mod_Q_Hab3/TEMP_VP/VP_Mu.feather --ncores 3 --chunk_size 50 &gt;&gt; datasets/processed/model_fitting/Mod_Q_Hab3/TEMP_VP/VP_Mu.log 2&gt;&amp;1
python3 VP_gemu.py --tr datasets/processed/model_fitting/Mod_Q_Hab4a/TEMP_VP/VP_Tr.feather --gamma datasets/processed/model_fitting/Mod_Q_Hab4a/TEMP_VP/VP_Gamma.feather --output datasets/processed/model_fitting/Mod_Q_Hab4a/TEMP_VP/VP_Mu.feather --ncores 3 --chunk_size 50 &gt;&gt; datasets/processed/model_fitting/Mod_Q_Hab4a/TEMP_VP/VP_Mu.log 2&gt;&amp;1
python3 VP_gemu.py --tr datasets/processed/model_fitting/Mod_Q_Hab4b/TEMP_VP/VP_Tr.feather --gamma datasets/processed/model_fitting/Mod_Q_Hab4b/TEMP_VP/VP_Gamma.feather --output datasets/processed/model_fitting/Mod_Q_Hab4b/TEMP_VP/VP_Mu.feather --ncores 3 --chunk_size 50 &gt;&gt; datasets/processed/model_fitting/Mod_Q_Hab4b/TEMP_VP/VP_Mu.log 2&gt;&amp;1
python3 VP_gemu.py --tr datasets/processed/model_fitting/Mod_Q_Hab10/TEMP_VP/VP_Tr.feather --gamma datasets/processed/model_fitting/Mod_Q_Hab10/TEMP_VP/VP_Gamma.feather --output datasets/processed/model_fitting/Mod_Q_Hab10/TEMP_VP/VP_Mu.feather --ncores 3 --chunk_size 50 &gt;&gt; datasets/processed/model_fitting/Mod_Q_Hab10/TEMP_VP/VP_Mu.log 2&gt;&amp;1
python3 VP_gemu.py --tr datasets/processed/model_fitting/Mod_Q_Hab12a/TEMP_VP/VP_Tr.feather --gamma datasets/processed/model_fitting/Mod_Q_Hab12a/TEMP_VP/VP_Gamma.feather --output datasets/processed/model_fitting/Mod_Q_Hab12a/TEMP_VP/VP_Mu.feather --ncores 3 --chunk_size 50 &gt;&gt; datasets/processed/model_fitting/Mod_Q_Hab12a/TEMP_VP/VP_Mu.log 2&gt;&amp;1
python3 VP_gemu.py --tr datasets/processed/model_fitting/Mod_Q_Hab12b/TEMP_VP/VP_Tr.feather --gamma datasets/processed/model_fitting/Mod_Q_Hab12b/TEMP_VP/VP_Gamma.feather --output datasets/processed/model_fitting/Mod_Q_Hab12b/TEMP_VP/VP_Mu.feather --ncores 3 --chunk_size 50 &gt;&gt; datasets/processed/model_fitting/Mod_Q_Hab12b/TEMP_VP/VP_Mu.log 2&gt;&amp;1
python3 VP_geta.py --tr datasets/processed/model_fitting/Mod_Q_Hab1/TEMP_VP/VP_Tr.feather --x datasets/processed/model_fitting/Mod_Q_Hab1/TEMP_VP/VP_X.feather --gamma datasets/processed/model_fitting/Mod_Q_Hab1/TEMP_VP/VP_Gamma.feather --output datasets/processed/model_fitting/Mod_Q_Hab1/TEMP_VP/VP_A.feather --ncores 3 --chunk_size 50 &gt;&gt; datasets/processed/model_fitting/Mod_Q_Hab1/TEMP_VP/VP_A.log 2&gt;&amp;1
python3 VP_geta.py --tr datasets/processed/model_fitting/Mod_Q_Hab2/TEMP_VP/VP_Tr.feather --x datasets/processed/model_fitting/Mod_Q_Hab2/TEMP_VP/VP_X.feather --gamma datasets/processed/model_fitting/Mod_Q_Hab2/TEMP_VP/VP_Gamma.feather --output datasets/processed/model_fitting/Mod_Q_Hab2/TEMP_VP/VP_A.feather --ncores 3 --chunk_size 50 &gt;&gt; datasets/processed/model_fitting/Mod_Q_Hab2/TEMP_VP/VP_A.log 2&gt;&amp;1
python3 VP_geta.py --tr datasets/processed/model_fitting/Mod_Q_Hab3/TEMP_VP/VP_Tr.feather --x datasets/processed/model_fitting/Mod_Q_Hab3/TEMP_VP/VP_X.feather --gamma datasets/processed/model_fitting/Mod_Q_Hab3/TEMP_VP/VP_Gamma.feather --output datasets/processed/model_fitting/Mod_Q_Hab3/TEMP_VP/VP_A.feather --ncores 3 --chunk_size 50 &gt;&gt; datasets/processed/model_fitting/Mod_Q_Hab3/TEMP_VP/VP_A.log 2&gt;&amp;1
python3 VP_geta.py --tr datasets/processed/model_fitting/Mod_Q_Hab4a/TEMP_VP/VP_Tr.feather --x datasets/processed/model_fitting/Mod_Q_Hab4a/TEMP_VP/VP_X.feather --gamma datasets/processed/model_fitting/Mod_Q_Hab4a/TEMP_VP/VP_Gamma.feather --output datasets/processed/model_fitting/Mod_Q_Hab4a/TEMP_VP/VP_A.feather --ncores 3 --chunk_size 50 &gt;&gt; datasets/processed/model_fitting/Mod_Q_Hab4a/TEMP_VP/VP_A.log 2&gt;&amp;1
python3 VP_geta.py --tr datasets/processed/model_fitting/Mod_Q_Hab4b/TEMP_VP/VP_Tr.feather --x datasets/processed/model_fitting/Mod_Q_Hab4b/TEMP_VP/VP_X.feather --gamma datasets/processed/model_fitting/Mod_Q_Hab4b/TEMP_VP/VP_Gamma.feather --output datasets/processed/model_fitting/Mod_Q_Hab4b/TEMP_VP/VP_A.feather --ncores 3 --chunk_size 50 &gt;&gt; datasets/processed/model_fitting/Mod_Q_Hab4b/TEMP_VP/VP_A.log 2&gt;&amp;1
python3 VP_geta.py --tr datasets/processed/model_fitting/Mod_Q_Hab10/TEMP_VP/VP_Tr.feather --x datasets/processed/model_fitting/Mod_Q_Hab10/TEMP_VP/VP_X.feather --gamma datasets/processed/model_fitting/Mod_Q_Hab10/TEMP_VP/VP_Gamma.feather --output datasets/processed/model_fitting/Mod_Q_Hab10/TEMP_VP/VP_A.feather --ncores 3 --chunk_size 50 &gt;&gt; datasets/processed/model_fitting/Mod_Q_Hab10/TEMP_VP/VP_A.log 2&gt;&amp;1
python3 VP_geta.py --tr datasets/processed/model_fitting/Mod_Q_Hab12a/TEMP_VP/VP_Tr.feather --x datasets/processed/model_fitting/Mod_Q_Hab12a/TEMP_VP/VP_X.feather --gamma datasets/processed/model_fitting/Mod_Q_Hab12a/TEMP_VP/VP_Gamma.feather --output datasets/processed/model_fitting/Mod_Q_Hab12a/TEMP_VP/VP_A.feather --ncores 3 --chunk_size 50 &gt;&gt; datasets/processed/model_fitting/Mod_Q_Hab12a/TEMP_VP/VP_A.log 2&gt;&amp;1
python3 VP_geta.py --tr datasets/processed/model_fitting/Mod_Q_Hab12b/TEMP_VP/VP_Tr.feather --x datasets/processed/model_fitting/Mod_Q_Hab12b/TEMP_VP/VP_X.feather --gamma datasets/processed/model_fitting/Mod_Q_Hab12b/TEMP_VP/VP_Gamma.feather --output datasets/processed/model_fitting/Mod_Q_Hab12b/TEMP_VP/VP_A.feather --ncores 3 --chunk_size 50 &gt;&gt; datasets/processed/model_fitting/Mod_Q_Hab12b/TEMP_VP/VP_A.log 2&gt;&amp;1
python3 VP_getf.py --x datasets/processed/model_fitting/Mod_Q_Hab1/TEMP_VP/VP_X.feather --beta_dir datasets/processed/model_fitting/Mod_Q_Hab1/TEMP_VP --output datasets/processed/model_fitting/Mod_Q_Hab1/TEMP_VP/VP_F.feather --ncores 3 &gt;&gt; datasets/processed/model_fitting/Mod_Q_Hab1/TEMP_VP/VP_F.log 2&gt;&amp;1
python3 VP_getf.py --x datasets/processed/model_fitting/Mod_Q_Hab2/TEMP_VP/VP_X.feather --beta_dir datasets/processed/model_fitting/Mod_Q_Hab2/TEMP_VP --output datasets/processed/model_fitting/Mod_Q_Hab2/TEMP_VP/VP_F.feather --ncores 3 &gt;&gt; datasets/processed/model_fitting/Mod_Q_Hab2/TEMP_VP/VP_F.log 2&gt;&amp;1
python3 VP_getf.py --x datasets/processed/model_fitting/Mod_Q_Hab3/TEMP_VP/VP_X.feather --beta_dir datasets/processed/model_fitting/Mod_Q_Hab3/TEMP_VP --output datasets/processed/model_fitting/Mod_Q_Hab3/TEMP_VP/VP_F.feather --ncores 3 &gt;&gt; datasets/processed/model_fitting/Mod_Q_Hab3/TEMP_VP/VP_F.log 2&gt;&amp;1
python3 VP_getf.py --x datasets/processed/model_fitting/Mod_Q_Hab4a/TEMP_VP/VP_X.feather --beta_dir datasets/processed/model_fitting/Mod_Q_Hab4a/TEMP_VP --output datasets/processed/model_fitting/Mod_Q_Hab4a/TEMP_VP/VP_F.feather --ncores 3 &gt;&gt; datasets/processed/model_fitting/Mod_Q_Hab4a/TEMP_VP/VP_F.log 2&gt;&amp;1
python3 VP_getf.py --x datasets/processed/model_fitting/Mod_Q_Hab4b/TEMP_VP/VP_X.feather --beta_dir datasets/processed/model_fitting/Mod_Q_Hab4b/TEMP_VP --output datasets/processed/model_fitting/Mod_Q_Hab4b/TEMP_VP/VP_F.feather --ncores 3 &gt;&gt; datasets/processed/model_fitting/Mod_Q_Hab4b/TEMP_VP/VP_F.log 2&gt;&amp;1
python3 VP_getf.py --x datasets/processed/model_fitting/Mod_Q_Hab10/TEMP_VP/VP_X.feather --beta_dir datasets/processed/model_fitting/Mod_Q_Hab10/TEMP_VP --output datasets/processed/model_fitting/Mod_Q_Hab10/TEMP_VP/VP_F.feather --ncores 3 &gt;&gt; datasets/processed/model_fitting/Mod_Q_Hab10/TEMP_VP/VP_F.log 2&gt;&amp;1
python3 VP_getf.py --x datasets/processed/model_fitting/Mod_Q_Hab12a/TEMP_VP/VP_X.feather --beta_dir datasets/processed/model_fitting/Mod_Q_Hab12a/TEMP_VP --output datasets/processed/model_fitting/Mod_Q_Hab12a/TEMP_VP/VP_F.feather --ncores 3 &gt;&gt; datasets/processed/model_fitting/Mod_Q_Hab12a/TEMP_VP/VP_F.log 2&gt;&amp;1
python3 VP_getf.py --x datasets/processed/model_fitting/Mod_Q_Hab12b/TEMP_VP/VP_X.feather --beta_dir datasets/processed/model_fitting/Mod_Q_Hab12b/TEMP_VP --output datasets/processed/model_fitting/Mod_Q_Hab12b/TEMP_VP/VP_F.feather --ncores 3 &gt;&gt; datasets/processed/model_fitting/Mod_Q_Hab12b/TEMP_VP/VP_F.log 2&gt;&amp;1</code></pre>
</div>
<p><br></p>
<button onclick="toggleScript('scriptContentNS6')" class="ShortBlockButton">
»» Example VP_SLURM.slurm file
</button>
<div id="scriptContentNS6" class="ShortBlock" style="display: none;">
<pre><code class="bash">#!/bin/bash
#SBATCH --job-name=VP_TF
#SBATCH --ntasks=1
#SBATCH --ntasks-per-node=1
#SBATCH --account=project_465001588
#SBATCH --cpus-per-task=1
#SBATCH --gpus-per-node=1
#SBATCH --time=01:30:00
#SBATCH --partition=small-g
#SBATCH --output=datasets/processed/model_fitting/Mod_Q_Hab_TF/log/%x-%A-%a.out
#SBATCH --error=datasets/processed/model_fitting/Mod_Q_Hab_TF/log/%x-%A-%a.out
#SBATCH --array=1-24

# File containing commands to be executed
File=datasets/processed/model_fitting/Mod_Q_Hab_TF/VP_Commands.txt

# Load TensorFlow module and configure environment
ml use /appl/local/csc/modulefiles
ml tensorflow
export TF_CPP_MIN_LOG_LEVEL=3
export TF_ENABLE_ONEDNN_OPTS=0

# Verify GPU availability
python3 -c "import tensorflow as tf; print(\"Num GPUs Available:\", len(tf.config.list_physical_devices(\"GPU\")))"

# Run array job
head -n $SLURM_ARRAY_TASK_ID $File | tail -n 1 | bash

echo End of program at `date`</code></pre>
</div>
<hr class="hr1">
</div>
</div>
<div class="section level2">
<h2 id="step-2-gpu">Step 2: GPU<a class="anchor" aria-label="anchor" href="#step-2-gpu"></a>
</h2>
<p>In this step, latent factor predictions and variance partitioning are
computed on GPUs. The batch jobs for these computations can be submitted
using the <code>sbatch</code> command:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="co"># Submit SLURM jobs for variance partitioning and latent factor predictions</span></span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a><span class="ex">sbatch</span> datasets/processed/model_fitting/Mod_Q_Hab_TF/VP_SLURM.slurm</span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a><span class="ex">sbatch</span> datasets/processed/model_fitting/Mod_Q_Hab_TF/LF_SLURM.slurm</span></code></pre></div>
<p>Additionally, cross-validated models are fitted by submitting the
corresponding SLURM scripts for each cross-validation strategy:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a><span class="co"># Submit SLURM jobs for cross-validated model fitting</span></span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb2-3"><a href="#cb2-3" tabindex="-1"></a><span class="co"># cross-validation method "CV_Dist"</span></span>
<span id="cb2-4"><a href="#cb2-4" tabindex="-1"></a><span class="ex">sbatch</span> datasets/processed/model_fitting/HabX/Model_Fitting_CV/CV_Bash_Fit_Dist.slurm</span>
<span id="cb2-5"><a href="#cb2-5" tabindex="-1"></a><span class="co"># cross-validation method "CV_Large"</span></span>
<span id="cb2-6"><a href="#cb2-6" tabindex="-1"></a><span class="ex">sbatch</span> datasets/processed/model_fitting/HabX/Model_Fitting_CV/CV_Bash_Fit_Large.slurm</span></code></pre></div>
<hr class="hr1">
</div>
<div class="section level2">
<h2 id="step-3-cpu">Step 3: CPU<a class="anchor" aria-label="anchor" href="#step-3-cpu"></a>
</h2>
<p>To continue the post-processing of the fitted models on CPUs, two
functions need to be executed:</p>
<div class="section level3">
<h3 id="mod_postprocess_2_cpu">1. <strong><code>mod_postprocess_2_CPU()</code></strong><a class="anchor" aria-label="anchor" href="#mod_postprocess_2_cpu"></a>
</h3>
<p>The <code><a href="../reference/Mod_postprocessing.html">mod_postprocess_2_CPU()</a></code> function progresses the
post-processing pipeline for HMSC models on the CPU by automating the
following tasks:</p>
<table class="table table table-condensed table-hover" style="font-size: 16px; margin-left: auto; margin-right: auto;"><tbody>
<tr>
<td style="text-align:left;padding-left: 2em;white-space: nowrap;" indentlevel="1">
<cc><code><a href="../reference/Response_curves.html">resp_curv_prepare_data()</a></code>,<br><code><a href="../reference/Response_curves.html">resp_curv_plot_SR()</a></code>,<br><code><a href="../reference/Response_curves.html">resp_curv_plot_species()</a></code>,<br><code><a href="../reference/Response_curves.html">resp_curv_plot_species_all()</a></code></cc><tab0></tab0>
</td>
<td style="text-align:left;">
continues the processing and visualisation of response curves.
</td>
</tr>
<tr>
<td style="text-align:left;padding-left: 2em;white-space: nowrap;" indentlevel="1">
<cc><code><a href="../reference/Predict_Maps.html">predict_maps()</a></code></cc><tab0></tab0>
</td>
<td style="text-align:left;">
<ul>
<li>
predicts habitat suitability across various climate scenarios.
</li>
<li>
computes the model’s explanatory power (internal evaluation without
cross-validation) using four metrics: AUC (area under the ROC curve),
RMSE (root mean square error), continuous Boyce index, and Tjur
R<sup>2</sup>.
</li>
<li>
prepares GeoTIFF maps for free access via the <code>IASDT</code>
<a href="http://opendap.biodt.eu/ias-pdt/" target="_blank" class="external-link ll">OPeNDAP
server</a> and the <code>IASDT</code>
<a href="https://app.biodt.eu/app/biodtshiny" target="_blank" class="external-link ll">Shiny
app</a>.
</li>
</ul>
</td>
</tr>
<tr>
<td style="text-align:left;padding-left: 2em;white-space: nowrap;" indentlevel="1">
<cc><code><a href="../reference/plot_prediction.html">plot_prediction()</a></code></cc><tab0></tab0>
</td>
<td style="text-align:left;">
visualises predictions of species and species richness as JPEG images.
</td>
</tr>
<tr>
<td style="text-align:left;padding-left: 2em;white-space: nowrap;" indentlevel="1">
<cc><code><a href="../reference/plot_latent_factor.html">plot_latent_factor()</a></code></cc><tab0></tab0>
</td>
<td style="text-align:left;">
visualises the spatial variation in site loadings of HMSC models as JPEG
images.
</td>
</tr>
<tr>
<td style="text-align:left;padding-left: 2em;white-space: nowrap;" indentlevel="1">
<cc><code><a href="../reference/Variance_partitioning.html">variance_partitioning_compute()</a></code>,<br><code><a href="../reference/Variance_partitioning.html">variance_partitioning_plot()</a></code></cc><tab0></tab0>
</td>
<td style="text-align:left;">
continues the processing and visualisation of variance partitioning.
</td>
</tr>
<tr>
<td style="text-align:left;padding-left: 2em;white-space: nowrap;" indentlevel="1">
<cc><code><a href="../reference/plot_evaluation.html">plot_evaluation()</a></code></cc><tab0></tab0>
</td>
<td style="text-align:left;">
visualises the explanatory power of the model (internal evaluation).
</td>
</tr>
</tbody></table>
<p><br></p>
</div>
<div class="section level3">
<h3 id="mod_postprocess_cv_1_cpu">2. <strong><code>mod_postprocess_CV_1_CPU()</code></strong><a class="anchor" aria-label="anchor" href="#mod_postprocess_cv_1_cpu"></a>
</h3>
<p>The <code><a href="../reference/Mod_postprocessing.html">mod_postprocess_CV_1_CPU()</a></code> function begins the
post-processing of cross-validated models on the CPU by automating the
following tasks:</p>
<table class="table table table-condensed table-hover" style="font-size: 16px; margin-left: auto; margin-right: auto;"><tbody>
<tr>
<td style="text-align:left;padding-left: 2em;white-space: nowrap;" indentlevel="1">
<cc><code><a href="../reference/Mod_Merge_Chains.html">mod_merge_chains_CV()</a></code></cc><tab0></tab0>
</td>
<td style="text-align:left;">
merges fitted cross-validated model chains into <code>Hmsc</code> model
objects and saves them to disk.
</td>
</tr>
<tr>
<td style="text-align:left;padding-left: 2em;white-space: nowrap;" indentlevel="1">
<cc><code><a href="../reference/Predict_Maps.html">predict_maps_CV()</a></code></cc><tab0></tab0>
</td>
<td style="text-align:left;">
prepares scripts for predicting latent factors for each cross-validation
strategy at new sampling units (evaluation folds). The arguments
<code>LF_only</code> and <code>LF_commands_only</code> are set to
<code>TRUE</code> to prepare only the necessary script files.
</td>
</tr>
</tbody></table>
<p>Once <code><a href="../reference/Predict_Maps.html">predict_maps_CV()</a></code> has been completed, the function
combines the computation commands into multiple text script files
(<ff>TF_Chunk_*.txt</ff>) in each model’s
<ff>Model_Fitting_CV/LF_TF_commands</ff> subdirectory. These scripts
need to be executed on GPUs using a single batch job submitted via a
SLURM script in the same directory, <ff>LF_SLURM.slurm</ff>.</p>
<hr class="hr1">
</div>
</div>
<div class="section level2">
<h2 id="step-4-gpu">Step 4: GPU<a class="anchor" aria-label="anchor" href="#step-4-gpu"></a>
</h2>
<p>In this step, the computation of latent factors for cross-validated
models is performed on GPUs using SLURM scripts.</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a><span class="ex">sbatch</span> datasets/processed/model_fitting/HabX/Model_Fitting_CV/LF_TF_commands/LF_SLURM.slurm</span></code></pre></div>
<hr class="hr1">
</div>
<div class="section level2">
<h2 id="step-5-cpu">Step 5: CPU<a class="anchor" aria-label="anchor" href="#step-5-cpu"></a>
</h2>
<p>The final step of the post-processing pipeline is carried out on CPUs
using the <code><a href="../reference/Mod_postprocessing.html">mod_postprocess_CV_2_CPU()</a></code> function. This
function automates the following tasks:</p>
<ul>
<li>Predicting habitat suitability at the testing cross-validation folds
using the <code><a href="../reference/Predict_Maps.html">predict_maps_CV()</a></code> function.</li>
<li>Computing the model’s predictive power (using spatially independent
testing data) with the same function, based on four metrics: AUC (area
under the ROC curve); RMSE (root mean square error); continuous Boyce
index; and Tjur R<sup>2</sup>.</li>
<li>Plotting the model’s evaluation, including:
<ul>
<li>Predictive power values for each evaluation metric versus the mean
number of testing presences</li>
<li>Explanatory versus predictive power for each evaluation metric</li>
</ul>
</li>
</ul>
<hr class="hr1">
<p><span style="font-size: 1.2em; line-height: 0.8;"> <b>Previous
articles:</b><br><tab>↠<tab><a href="workflow_1_overview.html" class="ll">1.
Overview</a><br><tab>↠<tab><a href="workflow_2_abiotic_data.html" class="ll">2.
Processing abiotic data</a><br><tab>↠<tab><a href="workflow_3_biotic_data.html" class="ll">3.
Processing biotic data</a><br><tab>↠<tab><a href="workflow_4_model_fitting.html" class="ll">4. Model
fitting</a><br></tab></tab></tab></tab></tab></tab></tab></tab></span></p>
</div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p>Developed by <a href="https://elgabbas.netlify.app/" class="external-link">Ahmed El-Gabbas</a>.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.3.</p>
</div>

    </footer>
</div>





  </body>
</html>
