<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>IAS-pDT modelling workflow — 5. Model post-processing • IASDT.R</title>
<script src="../lightswitch.js"></script><script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet">
<link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet">
<script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="IAS-pDT modelling workflow — 5. Model post-processing">
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top " aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">IASDT.R</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="Released version">0.1.04</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item"><a class="nav-link" href="../reference/index.html"><span class="fa fa-file-code-o"></span> Functions</a></li>
<li class="active nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-modelling-workflow" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true"><span class="fa fas fa-book"></span> Modelling workflow</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-modelling-workflow">
<li><a class="dropdown-item" href="../articles/workflow_1_overview.html">Overview</a></li>
    <li><a class="dropdown-item" href="../articles/workflow_2_abiotic_data.html">Processing abiotic data</a></li>
    <li><a class="dropdown-item" href="../articles/workflow_3_biotic_data.html">Processing biotic data</a></li>
    <li><a class="dropdown-item" href="../articles/workflow_4_model_fitting.html">Model fitting</a></li>
    <li><a class="dropdown-item" href="../articles/workflow_5_model_postprocess.html">Model post-processing</a></li>
  </ul>
</li>
      </ul>
<ul class="navbar-nav">
<li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json">
</form></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/BioDT/IASDT.R/" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
<li class="nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-lightswitch" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true" aria-label="Light switch"><span class="fa fa-sun"></span></button>
  <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="dropdown-lightswitch">
<li><button class="dropdown-item" data-bs-theme-value="light"><span class="fa fa-sun"></span> Light</button></li>
    <li><button class="dropdown-item" data-bs-theme-value="dark"><span class="fa fa-moon"></span> Dark</button></li>
    <li><button class="dropdown-item" data-bs-theme-value="auto"><span class="fa fa-adjust"></span> Auto</button></li>
  </ul>
</li>
      </ul>
</div>


  </div>
</nav><div class="container template-article">



<script src="workflow_5_model_postprocess_files/kePrint-0.0.1/kePrint.js"></script><link href="workflow_5_model_postprocess_files/lightable-0.0.1/lightable.css" rel="stylesheet">
<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">

      <h1>IAS-pDT modelling workflow — 5. Model post-processing</h1>
            
      
      <small class="dont-index">Source: <a href="https://github.com/BioDT/IASDT.R/blob/v0.1.04/vignettes/workflow_5_model_postprocess.Rmd" class="external-link"><code>vignettes/workflow_5_model_postprocess.Rmd</code></a></small>
      <div class="d-none name"><code>workflow_5_model_postprocess.Rmd</code></div>
    </div>

    
    
<script>
function toggleScript(id) {
  var content = document.getElementById(id);
  if (content.style.display === "none") {
    content.style.display = "block";
  } else {
    content.style.display = "none";
  }
}
</script><style>
/* Styles for the container div that holds the code block */
.ShortBlock {
  width: calc(100% - 40px);    /* Sets the width to 100% of the parent minus 40px to account for the left margin, ensuring it fits within the parent container */
  max-height: 400px;           /* Limits the maximum height to 400px; if content exceeds this, a vertical scrollbar will appear due to overflow-y */
  overflow-y: auto;            /* Enables a vertical scrollbar when content height exceeds max-height (400px), hides it when not needed */
  overflow-x: auto;            /* Enables a horizontal scrollbar when content width exceeds the div's width, hides it when not needed */
  margin-left: 40px;           /* Shifts the entire div (box and scrollbar) 40px to the right from the left edge of its parent, creating indentation */
  color: red;                  /* Sets the text color inside the div to red, applied to the <pre><code> content */
  display: block;              /* Ensures the div behaves as a block-level element, taking full width and stacking vertically */
  box-sizing: border-box;      /* Includes padding and border in the width calculation, preventing overflow beyond the calculated width */
  background-color: #f0f0f0;   /* Adds a light gray background for debugging, visually highlighting the div's area to check indentation */
  position: relative;          /* Sets the div's positioning context to relative, allowing absolute positioning of pseudo-elements (like ::before) within it */
  padding: 10px;               /* Adds 10px padding on all sides (top, right, bottom, left) for internal spacing between the div's edges and content */
}

/* Styles for the <pre> element inside .ShortBlock, which contains the code */
.ShortBlock pre {
  white-space: pre;            /* Preserves whitespace and prevents text wrapping, ensuring long lines extend horizontally as written */
  margin: 0;                   /* Removes default margins of the <pre> element to align it flush with the div's padded edges */
  width: max-content;          /* Sets the width to the natural width of the content (e.g., the longest line), enabling horizontal overflow if wider than the div */
  overflow: auto;              /* Adds scroll bars to the <pre> if its content overflows (though typically overridden by .ShortBlock's overflow-x/y) */
}

/* Customizes the appearance of the horizontal scrollbar for WebKit browsers (e.g., Chrome, Safari) */
.ShortBlock::-webkit-scrollbar {
  height: 10px;                /* Sets the height of the horizontal scrollbar to 10px, making it visible and sized consistently */
}

/* Creates a pseudo-element to simulate a top horizontal scrollbar area */
.ShortBlock::before {
  content: "";                 /* Defines an empty content for the pseudo-element, required to render it */
  display: block;              /* Makes the pseudo-element a block-level element, taking full width and stacking vertically */
  height: 10px;                /* Sets the height to 10px, matching the scrollbar size, creating a scrollable area at the top */
  width: 100%;                 /* Sets the width to 100% of the .ShortBlock div, aligning with its content area */
  position: absolute;          /* Positions the pseudo-element absolutely within the .ShortBlock (due to position: relative on parent) */
  top: 0;                      /* Aligns the pseudo-element to the top edge of the .ShortBlock div */
  left: 0;                     /* Aligns the pseudo-element to the left edge of the .ShortBlock div, starting at the padded edge */
  overflow-x: auto;            /* Enables horizontal scrolling for this pseudo-element, attempting to mirror the content's overflow (experimental) */
}

/* Styles for the button that toggles the collapsible code block */
.ShortBlockButton {
  color: red;                  /* Sets the button text color to red, matching the code block text */
  padding-left: 40px;          /* Adds 40px padding on the left, aligning the button text visually with the indented code block */
  border: none;                /* Removes the default border from the button for a clean look */
  background: none;            /* Removes the default background, making it transparent and minimal */
  cursor: pointer;             /* Changes the cursor to a pointer on hover, indicating the button is clickable */
}

ff {
  background-color: #def5ff;
  color: black;
  font-style: italic;
}

cc {
  background-color: #f0f7eb;
  color: black;
  font-style: italic;
}

.ll:visited {
  color: blue !important;
  text-decoration: none !important;
}

.ll:hover {
  text-decoration: underline !important;
  background-color: #d3f2aa !important;
  color: darkblue !important;
}

.ll:link, .ll:active {
  color: blue !important;
  text-decoration: none !important;
}

tab:before {
  content: "\00a0\00a0\00a0\00a0";
}

tab0:after {
  content: "\00a0\00a0";
}

table{
    width: 100% !important;
    margin-left: 50px !important;
}

table, th, td {
  padding: 1.8px !important;
  line-height: 1.3 !important;
}

.hr1 {
    width: 90%;
    margin-left: auto;
    margin-right: auto;
    border-top: 6px groove blue;
    margin: 30px auto;
    height: 4px;
    background-color: blue;
}

.hr2 {
    width: 50%;
    margin-left: auto;
    margin-right: auto;
    border-top: 6px groove orange;
    margin: 25px auto;
    height: 2px;
    background-color: orange;
}

br {
  display: block;
  margin: 4px 0;
}
</style>
<p><br></p>
<p>Post-processing of fitted models within the <code>IAS-pDT</code>
workflow is conducted across multiple steps, leveraging both CPU and GPU
computations to optimize performance and address memory constraints.</p>
<p><br></p>
<div class="section level2">
<h2 id="step-1-cpu">Step 1: CPU<a class="anchor" aria-label="anchor" href="#step-1-cpu"></a>
</h2>
<p>The <strong><code><a href="../reference/Mod_postprocessing.html">mod_postprocess_1_CPU()</a></code></strong> function
initiates the post-processing phase for each habitat type, automating
the following tasks:</p>
<table class="table table table-condensed table-hover" style="font-size: 16px; margin-left: auto; margin-right: auto;"><tbody>
<tr>
<td style="text-align:left;padding-left: 4em;white-space: nowrap;" indentlevel="1">
<cc><code><a href="../reference/Mod_SLURM.html">mod_SLURM_refit()</a></code></cc><tab0></tab0>
</td>
<td style="text-align:left;">
check for unsuccessful model fits
</td>
</tr>
<tr>
<td style="text-align:left;padding-left: 4em;white-space: nowrap;" indentlevel="1">
<cc><code><a href="../reference/Mod_Merge_Chains.html">mod_merge_chains()</a></code></cc><tab0></tab0>
</td>
<td style="text-align:left;">
merge MCMC chains and saves fitted model and coda objects to <i>.qs2</i>
or <i>.RData</i> files
</td>
</tr>
<tr>
<td style="text-align:left;padding-left: 4em;white-space: nowrap;" indentlevel="1">
<cc><code><a href="../reference/Convergence_Plot_All.html">convergence_plot_all()</a></code></cc><tab0></tab0>
</td>
<td style="text-align:left;">
visualize convergence of <code>rho</code>, <code>alpha</code>,
<code>omega</code>, and <code>beta</code> parameters across all model
variants; unnecessary for a single variant, this function compares
convergence across models with varying thinning values, both with and
without phylogenetic relationships, or GPP knot distances
</td>
</tr>
<tr>
<td style="text-align:left;padding-left: 4em;white-space: nowrap;" indentlevel="1">
<cc><code><a href="../reference/Convergence_plots.html">convergence_plot()</a></code></cc><tab0></tab0>
</td>
<td style="text-align:left;">
convergence of <code>rho</code>, <code>alpha</code>, <code>omega</code>,
and <code>beta</code> parameters for a selected model, offering a
detailed view compared to <code><a href="../reference/Convergence_Plot_All.html">convergence_plot_all()</a></code>
</td>
</tr>
<tr>
<td style="text-align:left;padding-left: 4em;white-space: nowrap;" indentlevel="1">
<cc><code><a href="../reference/plot_gelman.html">plot_gelman()</a></code></cc><tab0></tab0>
</td>
<td style="text-align:left;">
visualize Gelman-Rubin-Brooks diagnostics for the selected model
</td>
</tr>
<tr>
<td style="text-align:left;padding-left: 4em;white-space: nowrap;" indentlevel="1">
<cc><code><a href="../reference/Mod_Summary.html">mod_summary()</a></code></cc><tab0></tab0>
</td>
<td style="text-align:left;">
extract and save a summary of the model
</td>
</tr>
<tr>
<td style="text-align:left;padding-left: 4em;white-space: nowrap;" indentlevel="1">
<cc><code><a href="../reference/Parameter_Heatmap.html">mod_heatmap_beta()</a></code></cc><tab0></tab0>
</td>
<td style="text-align:left;">
generate heatmaps of the <code>beta</code> parameters
</td>
</tr>
<tr>
<td style="text-align:left;padding-left: 4em;white-space: nowrap;" indentlevel="1">
<cc><code><a href="../reference/Parameter_Heatmap.html">mod_heatmap_omega()</a></code></cc><tab0></tab0>
</td>
<td style="text-align:left;">
generates heatmaps of the <code>omega</code> parameter (residual species
associations)
</td>
</tr>
<tr>
<td style="text-align:left;padding-left: 4em;white-space: nowrap;" indentlevel="1">
<cc><code><a href="../reference/Mod_CV_Fit.html">mod_CV_fit()</a></code></cc><tab0></tab0>
</td>
<td style="text-align:left;">
prepare input data for spatial-block cross-validation model fitting
</td>
</tr>
</tbody></table>
<br><hr class="hr2">
<p><br></p>
<div class="section level3">
<h3 id="computationally-intensive-tasks-that-are-offloaded-to-gpu">Computationally intensive tasks that are offloaded to GPU<a class="anchor" aria-label="anchor" href="#computationally-intensive-tasks-that-are-offloaded-to-gpu"></a>
</h3>
<p>Previous attempts to prepare response curve data, predict at new
sites, and compute variance partitioning using R on CPUs (UFZ Windows
server and LUMI HPC) were hindered by memory limitations. Consequently,
these tasks are offloaded to GPU-based computations using Python and
TensorFlow. The <code><a href="../reference/Mod_postprocessing.html">mod_postprocess_1_CPU()</a></code> function invokes
the following sub-functions to generate commands for GPU execution:</p>
<table class="table table table-condensed table-hover" style="font-size: 16px; margin-left: auto; margin-right: auto;"><tbody>
<tr>
<td style="text-align:left;padding-left: 4em;white-space: nowrap;" indentlevel="1">
<cc><code><a href="../reference/Response_curves.html">resp_curv_prepare_data()</a></code></cc><tab0></tab0>
</td>
<td style="text-align:left;">
prepare data for predicting latent factors for response curves
</td>
</tr>
<tr>
<td style="text-align:left;padding-left: 4em;white-space: nowrap;" indentlevel="1">
<cc><code><a href="../reference/Predict_Maps.html">predict_maps()</a></code></cc><tab0></tab0>
</td>
<td style="text-align:left;">
prepare data for predicting latent factors at new sampling units
</td>
</tr>
<tr>
<td style="text-align:left;padding-left: 4em;white-space: nowrap;" indentlevel="1">
<cc><code><a href="../reference/Variance_partitioning.html">variance_partitioning_compute()</a></code></cc><tab0></tab0>
</td>
<td style="text-align:left;">
prepare data for computing variance partitioning
</td>
</tr>
</tbody></table>
<br><hr class="hr2">
<p><br></p>
</div>
<div class="section level3">
<h3 id="prepare-commands-for-gpu-computations">Prepare commands for GPU computations<a class="anchor" aria-label="anchor" href="#prepare-commands-for-gpu-computations"></a>
</h3>
<blockquote>
<p><u><i>Predicting latent factors:</i></u></p>
</blockquote>
<ul>
<li>Latent factor predictions for response curves and new sampling units
are executed via a <i>TensorFlow</i> script located at
<a href="https://github.com/BioDT/IASDT.R/blob/main/inst/crossprod_solve.py" target="_blank" class="external-link ll">inst/crossprod_solve.py</a>.</li>
<li>For these tasks, the respective R functions export numerous
<i>.qs2</i> and <i>.feather</i> data files to the <ff>TEMP_Pred</ff>
subdirectory, essential for GPU computations. They also generate
execution commands saved as <ff>LF_RC_Commands_<em>.txt</em></ff> (for
response curves) and <ff>LF_NewSites_Commands_.txt</ff> (for new
sites).</li>
</ul>
<button onclick="toggleScript('scriptContentNS1')" class="ShortBlockButton">
»» Example LF_RC_Commands.txt file
</button>
<div id="scriptContentNS1" class="ShortBlock" style="display: none;">
<pre><code class="bash">python3 crossprod_solve.py --s1 RC_c_s1.feather --s2 RC_c_s2.feather --post_eta RC_c_postEta_ch001.feather --path_out RC_c_etaPred_ch001.feather --denom 1200000 --chunk_size 1000 --threshold_mb 2000 --solve_chunk_size 50 --verbose  &gt;&gt; RC_c_etaPred_ch001.log 2&gt;&amp;1
python3 crossprod_solve.py --s1 RC_c_s1.feather --s2 RC_c_s2.feather --post_eta RC_c_postEta_ch002.feather --path_out RC_c_etaPred_ch002.feather --denom 1188081 --chunk_size 1000 --threshold_mb 2000 --solve_chunk_size 50 --verbose  &gt;&gt; RC_c_etaPred_ch002.log 2&gt;&amp;1
python3 crossprod_solve.py --s1 RC_c_s1.feather --s2 RC_c_s2.feather --post_eta RC_c_postEta_ch003.feather --path_out RC_c_etaPred_ch003.feather --denom 1176162 --chunk_size 1000 --threshold_mb 2000 --solve_chunk_size 50 --verbose  &gt;&gt; RC_c_etaPred_ch003.log 2&gt;&amp;1
python3 crossprod_solve.py --s1 RC_c_s1.feather --s2 RC_c_s2.feather --post_eta RC_c_postEta_ch004.feather --path_out RC_c_etaPred_ch004.feather --denom 1164242 --chunk_size 1000 --threshold_mb 2000 --solve_chunk_size 50 --verbose  &gt;&gt; RC_c_etaPred_ch004.log 2&gt;&amp;1
python3 crossprod_solve.py --s1 RC_c_s1.feather --s2 RC_c_s2.feather --post_eta RC_c_postEta_ch005.feather --path_out RC_c_etaPred_ch005.feather --denom 1200000 --chunk_size 1000 --threshold_mb 2000 --solve_chunk_size 50 --verbose  &gt;&gt; RC_c_etaPred_ch005.log 2&gt;&amp;1
python3 crossprod_solve.py --s1 RC_c_s1.feather --s2 RC_c_s2.feather --post_eta RC_c_postEta_ch006.feather --path_out RC_c_etaPred_ch006.feather --denom 413333 --chunk_size 1000 --threshold_mb 2000 --solve_chunk_size 50 --verbose  &gt;&gt; RC_c_etaPred_ch006.log 2&gt;&amp;1
python3 crossprod_solve.py --s1 RC_c_s1.feather --s2 RC_c_s2.feather --post_eta RC_c_postEta_ch007.feather --path_out RC_c_etaPred_ch007.feather --denom 1188081 --chunk_size 1000 --threshold_mb 2000 --solve_chunk_size 50 --verbose  &gt;&gt; RC_c_etaPred_ch007.log 2&gt;&amp;1
python3 crossprod_solve.py --s1 RC_c_s1.feather --s2 RC_c_s2.feather --post_eta RC_c_postEta_ch008.feather --path_out RC_c_etaPred_ch008.feather --denom 425253 --chunk_size 1000 --threshold_mb 2000 --solve_chunk_size 50 --verbose  &gt;&gt; RC_c_etaPred_ch008.log 2&gt;&amp;1
python3 crossprod_solve.py --s1 RC_c_s1.feather --s2 RC_c_s2.feather --post_eta RC_c_postEta_ch009.feather --path_out RC_c_etaPred_ch009.feather --denom 1176162 --chunk_size 1000 --threshold_mb 2000 --solve_chunk_size 50 --verbose  &gt;&gt; RC_c_etaPred_ch009.log 2&gt;&amp;1
python3 crossprod_solve.py --s1 RC_c_s1.feather --s2 RC_c_s2.feather --post_eta RC_c_postEta_ch010.feather --path_out RC_c_etaPred_ch010.feather --denom 437172 --chunk_size 1000 --threshold_mb 2000 --solve_chunk_size 50 --verbose  &gt;&gt; RC_c_etaPred_ch010.log 2&gt;&amp;1
python3 crossprod_solve.py --s1 RC_c_s1.feather --s2 RC_c_s2.feather --post_eta RC_c_postEta_ch011.feather --path_out RC_c_etaPred_ch011.feather --denom 1200000 --chunk_size 1000 --threshold_mb 2000 --solve_chunk_size 50 --verbose  &gt;&gt; RC_c_etaPred_ch011.log 2&gt;&amp;1
python3 crossprod_solve.py --s1 RC_c_s1.feather --s2 RC_c_s2.feather --post_eta RC_c_postEta_ch012.feather --path_out RC_c_etaPred_ch012.feather --denom 401414 --chunk_size 1000 --threshold_mb 2000 --solve_chunk_size 50 --verbose  &gt;&gt; RC_c_etaPred_ch012.log 2&gt;&amp;1
python3 crossprod_solve.py --s1 RC_c_s1.feather --s2 RC_c_s2.feather --post_eta RC_c_postEta_ch013.feather --path_out RC_c_etaPred_ch013.feather --denom 1164242 --chunk_size 1000 --threshold_mb 2000 --solve_chunk_size 50 --verbose  &gt;&gt; RC_c_etaPred_ch013.log 2&gt;&amp;1
python3 crossprod_solve.py --s1 RC_c_s1.feather --s2 RC_c_s2.feather --post_eta RC_c_postEta_ch014.feather --path_out RC_c_etaPred_ch014.feather --denom 449091 --chunk_size 1000 --threshold_mb 2000 --solve_chunk_size 50 --verbose  &gt;&gt; RC_c_etaPred_ch014.log 2&gt;&amp;1
python3 crossprod_solve.py --s1 RC_c_s1.feather --s2 RC_c_s2.feather --post_eta RC_c_postEta_ch015.feather --path_out RC_c_etaPred_ch015.feather --denom 1152323 --chunk_size 1000 --threshold_mb 2000 --solve_chunk_size 50 --verbose  &gt;&gt; RC_c_etaPred_ch015.log 2&gt;&amp;1</code></pre>
</div>
<p><br></p>
<button onclick="toggleScript('scriptContentNS2')" class="ShortBlockButton">
»» Example LF_NewSites_Commands.txt file
</button>
<div id="scriptContentNS2" class="ShortBlock" style="display: none;">
<pre><code class="bash">python3 crossprod_solve.py --s1 LF_3_Test_s1.feather --s2 LF_3_Test_s2.feather --post_eta LF_3_Test_postEta_ch001.feather --path_out LF_3_Test_etaPred_ch001.feather --denom 225758 --chunk_size 1000 --threshold_mb 2000 --solve_chunk_size 50 --verbose  &gt;&gt; LF_3_Test_etaPred_ch001.log 2&gt;&amp;1
python3 crossprod_solve.py --s1 LF_3_Test_s1.feather --s2 LF_3_Test_s2.feather --post_eta LF_3_Test_postEta_ch002.feather --path_out LF_3_Test_etaPred_ch002.feather --denom 211111 --chunk_size 1000 --threshold_mb 2000 --solve_chunk_size 50 --verbose  &gt;&gt; LF_3_Test_etaPred_ch002.log 2&gt;&amp;1
python3 crossprod_solve.py --s1 LF_3_Test_s1.feather --s2 LF_3_Test_s2.feather --post_eta LF_3_Test_postEta_ch003.feather --path_out LF_3_Test_etaPred_ch003.feather --denom 240404 --chunk_size 1000 --threshold_mb 2000 --solve_chunk_size 50 --verbose  &gt;&gt; LF_3_Test_etaPred_ch003.log 2&gt;&amp;1
python3 crossprod_solve.py --s1 LF_3_Test_s1.feather --s2 LF_3_Test_s2.feather --post_eta LF_3_Test_postEta_ch004.feather --path_out LF_3_Test_etaPred_ch004.feather --denom 196465 --chunk_size 1000 --threshold_mb 2000 --solve_chunk_size 50 --verbose  &gt;&gt; LF_3_Test_etaPred_ch004.log 2&gt;&amp;1
python3 crossprod_solve.py --s1 LF_3_Test_s1.feather --s2 LF_3_Test_s2.feather --post_eta LF_3_Test_postEta_ch005.feather --path_out LF_3_Test_etaPred_ch005.feather --denom 196465 --chunk_size 1000 --threshold_mb 2000 --solve_chunk_size 50 --verbose  &gt;&gt; LF_3_Test_etaPred_ch005.log 2&gt;&amp;1
python3 crossprod_solve.py --s1 LF_3_Test_s1.feather --s2 LF_3_Test_s2.feather --post_eta LF_3_Test_postEta_ch006.feather --path_out LF_3_Test_etaPred_ch006.feather --denom 211111 --chunk_size 1000 --threshold_mb 2000 --solve_chunk_size 50 --verbose  &gt;&gt; LF_3_Test_etaPred_ch006.log 2&gt;&amp;1
python3 crossprod_solve.py --s1 LF_3_Test_s1.feather --s2 LF_3_Test_s2.feather --post_eta LF_3_Test_postEta_ch007.feather --path_out LF_3_Test_etaPred_ch007.feather --denom 225758 --chunk_size 1000 --threshold_mb 2000 --solve_chunk_size 50 --verbose  &gt;&gt; LF_3_Test_etaPred_ch007.log 2&gt;&amp;1
python3 crossprod_solve.py --s1 LF_3_Test_s1.feather --s2 LF_3_Test_s2.feather --post_eta LF_3_Test_postEta_ch008.feather --path_out LF_3_Test_etaPred_ch008.feather --denom 181818 --chunk_size 1000 --threshold_mb 2000 --solve_chunk_size 50 --verbose  &gt;&gt; LF_3_Test_etaPred_ch008.log 2&gt;&amp;1
python3 crossprod_solve.py --s1 LF_3_Test_s1.feather --s2 LF_3_Test_s2.feather --post_eta LF_3_Test_postEta_ch009.feather --path_out LF_3_Test_etaPred_ch009.feather --denom 255051 --chunk_size 1000 --threshold_mb 2000 --solve_chunk_size 50 --verbose  &gt;&gt; LF_3_Test_etaPred_ch009.log 2&gt;&amp;1
python3 crossprod_solve.py --s1 LF_3_Test_s1.feather --s2 LF_3_Test_s2.feather --post_eta LF_3_Test_postEta_ch010.feather --path_out LF_3_Test_etaPred_ch010.feather --denom 240404 --chunk_size 1000 --threshold_mb 2000 --solve_chunk_size 50 --verbose  &gt;&gt; LF_3_Test_etaPred_ch010.log 2&gt;&amp;1
python3 crossprod_solve.py --s1 LF_3_Test_s1.feather --s2 LF_3_Test_s2.feather --post_eta LF_3_Test_postEta_ch011.feather --path_out LF_3_Test_etaPred_ch011.feather --denom 167172 --chunk_size 1000 --threshold_mb 2000 --solve_chunk_size 50 --verbose  &gt;&gt; LF_3_Test_etaPred_ch011.log 2&gt;&amp;1
python3 crossprod_solve.py --s1 LF_3_Test_s1.feather --s2 LF_3_Test_s2.feather --post_eta LF_3_Test_postEta_ch012.feather --path_out LF_3_Test_etaPred_ch012.feather --denom 269697 --chunk_size 1000 --threshold_mb 2000 --solve_chunk_size 50 --verbose  &gt;&gt; LF_3_Test_etaPred_ch012.log 2&gt;&amp;1
python3 crossprod_solve.py --s1 LF_3_Test_s1.feather --s2 LF_3_Test_s2.feather --post_eta LF_3_Test_postEta_ch013.feather --path_out LF_3_Test_etaPred_ch013.feather --denom 255051 --chunk_size 1000 --threshold_mb 2000 --solve_chunk_size 50 --verbose  &gt;&gt; LF_3_Test_etaPred_ch013.log 2&gt;&amp;1
python3 crossprod_solve.py --s1 LF_3_Test_s1.feather --s2 LF_3_Test_s2.feather --post_eta LF_3_Test_postEta_ch014.feather --path_out LF_3_Test_etaPred_ch014.feather --denom 269697 --chunk_size 1000 --threshold_mb 2000 --solve_chunk_size 50 --verbose  &gt;&gt; LF_3_Test_etaPred_ch014.log 2&gt;&amp;1
python3 crossprod_solve.py --s1 LF_3_Test_s1.feather --s2 LF_3_Test_s2.feather --post_eta LF_3_Test_postEta_ch015.feather --path_out LF_3_Test_etaPred_ch015.feather --denom 181818 --chunk_size 1000 --threshold_mb 2000 --solve_chunk_size 50 --verbose  &gt;&gt; LF_3_Test_etaPred_ch015.log 2&gt;&amp;1</code></pre>
</div>
<p><br><br></p>
<ul>
<li>Response curves
<ul>
<li>
<code><a href="../reference/Response_curves.html">resp_curv_prepare_data()</a></code> extends
<code><a href="https://rdrr.io/pkg/Hmsc/man/constructGradient.html" class="external-link">Hmsc::constructGradient()</a></code> and
<code><a href="https://rdrr.io/pkg/Hmsc/man/plotGradient.html" class="external-link">Hmsc::plotGradient()</a></code>, enabling GPU-based response curve
data preparation when
<cc><code>LF_commands_only = TRUE</code></cc>.</li>
<li>To predict at mean coordinates (per the <i>coordinates</i> argument
of <code><a href="https://rdrr.io/pkg/Hmsc/man/constructGradient.html" class="external-link">Hmsc::constructGradient()</a></code>), latent factor
predictions—typically memory-intensive with
<code><a href="https://rdrr.io/pkg/Hmsc/man/predictLatentFactor.html" class="external-link">Hmsc::predictLatentFactor()</a></code>—are computed on GPUs.</li>
</ul>
</li>
<li>Predicting at new sites
<ul>
<li>
<code><a href="../reference/Predict_Maps.html">predict_maps()</a></code> prepares GPU computations for new site
predictions when <cc><code>LF_only = TRUE</code></cc> and
<cc><code>LF_commands_only = TRUE</code></cc>.</li>
</ul>
</li>
</ul>
<p><br><br></p>
<blockquote>
<p><u><i>Computing variance partitioning:</i></u></p>
</blockquote>
<ul>
<li>Variance partitioning computations on GPUs are executed using
TensorFlow scripts at
<a href="https://github.com/BioDT/IASDT.R/blob/main/inst/VP_geta.py" target="_blank" class="external-link ll">inst/VP_geta.py</a>,
<a href="https://github.com/BioDT/IASDT.R/blob/main/inst/VP_getf.py" target="_blank" class="external-link ll">inst/VP_getf.py</a>,
and
<a href="https://github.com/BioDT/IASDT.R/blob/main/inst/VP_gemu.py" target="_blank" class="external-link ll">inst/VP_gemu.py</a>.
The functionality of these scripts was taken from
<code><a href="https://rdrr.io/pkg/Hmsc/man/computeVariancePartitioning.html" class="external-link">Hmsc::computeVariancePartitioning()</a></code> (see the
<code>geta</code>, <code>getf</code>, and <code>gemu</code> internal
functions identified inside of the computeVariancePartitioning R
function).</li>
<li>
<code><a href="../reference/Variance_partitioning.html">variance_partitioning_compute()</a></code> exports required files
to the <ff>TEMP_VP</ff> subdirectory, including numerous <i>.qs2</i> and
<i>.feather</i> files, and generates execution commands saved as
<ff>VP_A_Command.txt</ff>, <ff>VP_F_Command.txt</ff>, and
<ff>VP_mu_Command.txt</ff>.</li>
</ul>
<p><br><br></p>
</div>
<div class="section level3">
<h3 id="combining-commands-for-gpu-computations">Combining commands for GPU computations<a class="anchor" aria-label="anchor" href="#combining-commands-for-gpu-computations"></a>
</h3>
<p>After executing <code><a href="../reference/Mod_postprocessing.html">mod_postprocess_1_CPU()</a></code> for all habitat
types, the <strong><code><a href="../reference/Mod_postprocessing.html">mod_prepare_TF()</a></code></strong> function
consolidates batch scripts for GPU computations across all habitat
types:</p>
<ul>
<li>It aggregates script files containing commands for response curves
and latent factor predictions, splitting them into multiple scripts
(<ff>TF_Chunk_*.txt</ff>) for batch processing, and generates a SLURM
script (<ff>LF_SLURM.slurm</ff>) for latent factor predictions.</li>
</ul>
<button onclick="toggleScript('scriptContentNS3')" class="ShortBlockButton">
»» Example TF_Chunk_*.txt file
</button>
<div id="scriptContentNS3" class="ShortBlock" style="display: none;">
<pre><code class="bash">#!/bin/bash

# Load TensorFlow module and configure environment
ml use /appl/local/csc/modulefiles
ml tensorflow
export TF_CPP_MIN_LOG_LEVEL=3
export TF_ENABLE_ONEDNN_OPTS=0

# Verify GPU availability
python3 -c "import tensorflow as tf; print(\"Num GPUs Available:\", len(tf.config.list_physical_devices(\"GPU\")))"

# 20 commands to be executed:
python3 crossprod_solve.py --s1 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_s1.feather' --s2 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_s2.feather' --post_eta 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_postEta_ch001.feather' --path_out 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_etaPred_ch001.feather' --denom 50000 --chunk_size 1000 --threshold_mb 2000 --solve_chunk_size 50 --verbose  &gt;&gt; datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_etaPred_ch001.log 2&gt;&amp;1
python3 crossprod_solve.py --s1 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_s1.feather' --s2 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_s2.feather' --post_eta 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_postEta_ch002.feather' --path_out 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_etaPred_ch002.feather' --denom 1470707 --chunk_size 1000 --threshold_mb 2000 --solve_chunk_size 50 --verbose  &gt;&gt; datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_etaPred_ch002.log 2&gt;&amp;1
python3 crossprod_solve.py --s1 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_s1.feather' --s2 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_s2.feather' --post_eta 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_postEta_ch003.feather' --path_out 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_etaPred_ch003.feather' --denom 1485354 --chunk_size 1000 --threshold_mb 2000 --solve_chunk_size 50 --verbose  &gt;&gt; datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_etaPred_ch003.log 2&gt;&amp;1
python3 crossprod_solve.py --s1 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_s1.feather' --s2 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_s2.feather' --post_eta 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_postEta_ch004.feather' --path_out 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_etaPred_ch004.feather' --denom 1456061 --chunk_size 1000 --threshold_mb 2000 --solve_chunk_size 50 --verbose  &gt;&gt; datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_etaPred_ch004.log 2&gt;&amp;1
python3 crossprod_solve.py --s1 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_s1.feather' --s2 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_s2.feather' --post_eta 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_postEta_ch005.feather' --path_out 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_etaPred_ch005.feather' --denom 1500000 --chunk_size 1000 --threshold_mb 2000 --solve_chunk_size 50 --verbose  &gt;&gt; datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_etaPred_ch005.log 2&gt;&amp;1
python3 crossprod_solve.py --s1 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_s1.feather' --s2 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_s2.feather' --post_eta 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_postEta_ch006.feather' --path_out 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_etaPred_ch006.feather' --denom 1500000 --chunk_size 1000 --threshold_mb 2000 --solve_chunk_size 50 --verbose  &gt;&gt; datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_etaPred_ch006.log 2&gt;&amp;1
python3 crossprod_solve.py --s1 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_s1.feather' --s2 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_s2.feather' --post_eta 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_postEta_ch007.feather' --path_out 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_etaPred_ch007.feather' --denom 1426768 --chunk_size 1000 --threshold_mb 2000 --solve_chunk_size 50 --verbose  &gt;&gt; datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_etaPred_ch007.log 2&gt;&amp;1
python3 crossprod_solve.py --s1 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_s1.feather' --s2 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_s2.feather' --post_eta 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_postEta_ch008.feather' --path_out 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_etaPred_ch008.feather' --denom 1470707 --chunk_size 1000 --threshold_mb 2000 --solve_chunk_size 50 --verbose  &gt;&gt; datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_etaPred_ch008.log 2&gt;&amp;1
python3 crossprod_solve.py --s1 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_s1.feather' --s2 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_s2.feather' --post_eta 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_postEta_ch009.feather' --path_out 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_etaPred_ch009.feather' --denom 1485354 --chunk_size 1000 --threshold_mb 2000 --solve_chunk_size 50 --verbose  &gt;&gt; datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_etaPred_ch009.log 2&gt;&amp;1
python3 crossprod_solve.py --s1 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_s1.feather' --s2 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_s2.feather' --post_eta 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_postEta_ch010.feather' --path_out 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_etaPred_ch010.feather' --denom 1456061 --chunk_size 1000 --threshold_mb 2000 --solve_chunk_size 50 --verbose  &gt;&gt; datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_etaPred_ch010.log 2&gt;&amp;1
python3 crossprod_solve.py --s1 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_s1.feather' --s2 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_s2.feather' --post_eta 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_postEta_ch011.feather' --path_out 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_etaPred_ch011.feather' --denom 1470707 --chunk_size 1000 --threshold_mb 2000 --solve_chunk_size 50 --verbose  &gt;&gt; datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_etaPred_ch011.log 2&gt;&amp;1
python3 crossprod_solve.py --s1 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_s1.feather' --s2 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_s2.feather' --post_eta 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_postEta_ch012.feather' --path_out 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_etaPred_ch012.feather' --denom 1412121 --chunk_size 1000 --threshold_mb 2000 --solve_chunk_size 50 --verbose  &gt;&gt; datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_etaPred_ch012.log 2&gt;&amp;1
python3 crossprod_solve.py --s1 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_s1.feather' --s2 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_s2.feather' --post_eta 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_postEta_ch013.feather' --path_out 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_etaPred_ch013.feather' --denom 1426768 --chunk_size 1000 --threshold_mb 2000 --solve_chunk_size 50 --verbose  &gt;&gt; datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_etaPred_ch013.log 2&gt;&amp;1
python3 crossprod_solve.py --s1 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_s1.feather' --s2 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_s2.feather' --post_eta 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_postEta_ch014.feather' --path_out 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_etaPred_ch014.feather' --denom 1426768 --chunk_size 1000 --threshold_mb 2000 --solve_chunk_size 50 --verbose  &gt;&gt; datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_etaPred_ch014.log 2&gt;&amp;1
python3 crossprod_solve.py --s1 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_s1.feather' --s2 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_s2.feather' --post_eta 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_postEta_ch015.feather' --path_out 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_etaPred_ch015.feather' --denom 1441414 --chunk_size 1000 --threshold_mb 2000 --solve_chunk_size 50 --verbose  &gt;&gt; datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_etaPred_ch015.log 2&gt;&amp;1
python3 crossprod_solve.py --s1 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_s1.feather' --s2 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_s2.feather' --post_eta 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_postEta_ch016.feather' --path_out 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_etaPred_ch016.feather' --denom 1456061 --chunk_size 1000 --threshold_mb 2000 --solve_chunk_size 50 --verbose  &gt;&gt; datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_etaPred_ch016.log 2&gt;&amp;1
python3 crossprod_solve.py --s1 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_s1.feather' --s2 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_s2.feather' --post_eta 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_postEta_ch017.feather' --path_out 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_etaPred_ch017.feather' --denom 1441414 --chunk_size 1000 --threshold_mb 2000 --solve_chunk_size 50 --verbose  &gt;&gt; datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_etaPred_ch017.log 2&gt;&amp;1
python3 crossprod_solve.py --s1 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_s1.feather' --s2 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_s2.feather' --post_eta 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_postEta_ch018.feather' --path_out 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_etaPred_ch018.feather' --denom 1382828 --chunk_size 1000 --threshold_mb 2000 --solve_chunk_size 50 --verbose  &gt;&gt; datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_etaPred_ch018.log 2&gt;&amp;1
python3 crossprod_solve.py --s1 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_s1.feather' --s2 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_s2.feather' --post_eta 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_postEta_ch019.feather' --path_out 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_etaPred_ch019.feather' --denom 1485354 --chunk_size 1000 --threshold_mb 2000 --solve_chunk_size 50 --verbose  &gt;&gt; datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_etaPred_ch019.log 2&gt;&amp;1
python3 crossprod_solve.py --s1 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_s1.feather' --s2 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_s2.feather' --post_eta 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_postEta_ch020.feather' --path_out 'datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_etaPred_ch020.feather' --denom 1368182 --chunk_size 1000 --threshold_mb 2000 --solve_chunk_size 50 --verbose  &gt;&gt; datasets/processed/model_fitting/Mod_Riv_Hab1/TEMP_Pred/LF_1_Test_etaPred_ch020.log 2&gt;&amp;1</code></pre>
</div>
<p><br></p>
<button onclick="toggleScript('scriptContentNS4')" class="ShortBlockButton">
»» Example LF_SLURM.slurm file
</button>
<div id="scriptContentNS4" class="ShortBlock" style="display: none;">
<pre><code class="bash">#!/bin/bash
#SBATCH --job-name=PP_LF
#SBATCH --ntasks=1
#SBATCH --ntasks-per-node=1
#SBATCH --account=project_465001588
#SBATCH --cpus-per-task=1
#SBATCH --gpus-per-node=1
#SBATCH --time=01:00:00
#SBATCH --partition=small-g
#SBATCH --output=datasets/processed/model_fitting/TMP/%x-%A-%a.out
#SBATCH --error=datasets/processed/model_fitting/TMP/%x-%A-%a.out
#SBATCH --array=1-186

# Define directories
OutputDir="datasets/processed/model_fitting/TF_BatchFiles"

# Find all the split files and sort them explicitly
SplitFiles=($(find "$OutputDir" -type f -name "TF_Chunk_*.txt" | sort -V))

# Check if files were found
if [ ${#SplitFiles[@]} -eq 0 ]; then
    echo "Error: No files matching TF_Chunk_*.txt found in $OutputDir"
    exit 1
fi

# Ensure no more than `, NumFiles, ` files are processed
MaxFiles=186
if [ ${#SplitFiles[@]} -gt $MaxFiles ]; then
    SplitFiles=("${SplitFiles[@]:0:$MaxFiles}")
    echo "More than $MaxFiles files found, limiting to the first $MaxFiles files."
fi

# Get the index of the current task based on SLURM_ARRAY_TASK_ID
TaskIndex=$((SLURM_ARRAY_TASK_ID - 1))

# Validate TaskIndex
if [ $TaskIndex -ge ${#SplitFiles[@]} ] || [ $TaskIndex -lt 0 ]; then
    echo "Error: TaskIndex $TaskIndex is out of range. Valid range: 0 to $((${#SplitFiles[@]} - 1))"
    exit 1
fi

# Get the specific split file to process based on the job array task ID
SplitFile="${SplitFiles[$TaskIndex]}"

# Verify the selected split file
if [ -z "$SplitFile" ] || [ ! -f "$SplitFile" ]; then
    echo "Error: File $SplitFile does not exist or is invalid."
    exit 1
fi

# Processing file
echo "Processing file: $SplitFile"

# Run the selected split file
bash "$SplitFile"

echo End of program at `date`</code></pre>
</div>
<p><br></p>
<ul>
<li>It consolidates variance partitioning command files into a single
<ff>VP_Commands.txt</ff> and prepares a SLURM script
(<ff>VP_SLURM.slurm</ff>) for variance partitioning computations.</li>
</ul>
<button onclick="toggleScript('scriptContentNS5')" class="ShortBlockButton">
»» Example VP_Commands.txt file
</button>
<div id="scriptContentNS5" class="ShortBlock" style="display: none;">
<pre><code class="bash">python3 VP_gemu.py --tr datasets/processed/model_fitting/Mod_Q_Hab1/TEMP_VP/VP_Tr.feather --gamma datasets/processed/model_fitting/Mod_Q_Hab1/TEMP_VP/VP_Gamma.feather --output datasets/processed/model_fitting/Mod_Q_Hab1/TEMP_VP/VP_Mu.feather --ncores 3 --chunk_size 50 &gt;&gt; datasets/processed/model_fitting/Mod_Q_Hab1/TEMP_VP/VP_Mu.log 2&gt;&amp;1
python3 VP_gemu.py --tr datasets/processed/model_fitting/Mod_Q_Hab2/TEMP_VP/VP_Tr.feather --gamma datasets/processed/model_fitting/Mod_Q_Hab2/TEMP_VP/VP_Gamma.feather --output datasets/processed/model_fitting/Mod_Q_Hab2/TEMP_VP/VP_Mu.feather --ncores 3 --chunk_size 50 &gt;&gt; datasets/processed/model_fitting/Mod_Q_Hab2/TEMP_VP/VP_Mu.log 2&gt;&amp;1
python3 VP_gemu.py --tr datasets/processed/model_fitting/Mod_Q_Hab3/TEMP_VP/VP_Tr.feather --gamma datasets/processed/model_fitting/Mod_Q_Hab3/TEMP_VP/VP_Gamma.feather --output datasets/processed/model_fitting/Mod_Q_Hab3/TEMP_VP/VP_Mu.feather --ncores 3 --chunk_size 50 &gt;&gt; datasets/processed/model_fitting/Mod_Q_Hab3/TEMP_VP/VP_Mu.log 2&gt;&amp;1
python3 VP_gemu.py --tr datasets/processed/model_fitting/Mod_Q_Hab4a/TEMP_VP/VP_Tr.feather --gamma datasets/processed/model_fitting/Mod_Q_Hab4a/TEMP_VP/VP_Gamma.feather --output datasets/processed/model_fitting/Mod_Q_Hab4a/TEMP_VP/VP_Mu.feather --ncores 3 --chunk_size 50 &gt;&gt; datasets/processed/model_fitting/Mod_Q_Hab4a/TEMP_VP/VP_Mu.log 2&gt;&amp;1
python3 VP_gemu.py --tr datasets/processed/model_fitting/Mod_Q_Hab4b/TEMP_VP/VP_Tr.feather --gamma datasets/processed/model_fitting/Mod_Q_Hab4b/TEMP_VP/VP_Gamma.feather --output datasets/processed/model_fitting/Mod_Q_Hab4b/TEMP_VP/VP_Mu.feather --ncores 3 --chunk_size 50 &gt;&gt; datasets/processed/model_fitting/Mod_Q_Hab4b/TEMP_VP/VP_Mu.log 2&gt;&amp;1
python3 VP_gemu.py --tr datasets/processed/model_fitting/Mod_Q_Hab10/TEMP_VP/VP_Tr.feather --gamma datasets/processed/model_fitting/Mod_Q_Hab10/TEMP_VP/VP_Gamma.feather --output datasets/processed/model_fitting/Mod_Q_Hab10/TEMP_VP/VP_Mu.feather --ncores 3 --chunk_size 50 &gt;&gt; datasets/processed/model_fitting/Mod_Q_Hab10/TEMP_VP/VP_Mu.log 2&gt;&amp;1
python3 VP_gemu.py --tr datasets/processed/model_fitting/Mod_Q_Hab12a/TEMP_VP/VP_Tr.feather --gamma datasets/processed/model_fitting/Mod_Q_Hab12a/TEMP_VP/VP_Gamma.feather --output datasets/processed/model_fitting/Mod_Q_Hab12a/TEMP_VP/VP_Mu.feather --ncores 3 --chunk_size 50 &gt;&gt; datasets/processed/model_fitting/Mod_Q_Hab12a/TEMP_VP/VP_Mu.log 2&gt;&amp;1
python3 VP_gemu.py --tr datasets/processed/model_fitting/Mod_Q_Hab12b/TEMP_VP/VP_Tr.feather --gamma datasets/processed/model_fitting/Mod_Q_Hab12b/TEMP_VP/VP_Gamma.feather --output datasets/processed/model_fitting/Mod_Q_Hab12b/TEMP_VP/VP_Mu.feather --ncores 3 --chunk_size 50 &gt;&gt; datasets/processed/model_fitting/Mod_Q_Hab12b/TEMP_VP/VP_Mu.log 2&gt;&amp;1
python3 VP_geta.py --tr datasets/processed/model_fitting/Mod_Q_Hab1/TEMP_VP/VP_Tr.feather --x datasets/processed/model_fitting/Mod_Q_Hab1/TEMP_VP/VP_X.feather --gamma datasets/processed/model_fitting/Mod_Q_Hab1/TEMP_VP/VP_Gamma.feather --output datasets/processed/model_fitting/Mod_Q_Hab1/TEMP_VP/VP_A.feather --ncores 3 --chunk_size 50 &gt;&gt; datasets/processed/model_fitting/Mod_Q_Hab1/TEMP_VP/VP_A.log 2&gt;&amp;1
python3 VP_geta.py --tr datasets/processed/model_fitting/Mod_Q_Hab2/TEMP_VP/VP_Tr.feather --x datasets/processed/model_fitting/Mod_Q_Hab2/TEMP_VP/VP_X.feather --gamma datasets/processed/model_fitting/Mod_Q_Hab2/TEMP_VP/VP_Gamma.feather --output datasets/processed/model_fitting/Mod_Q_Hab2/TEMP_VP/VP_A.feather --ncores 3 --chunk_size 50 &gt;&gt; datasets/processed/model_fitting/Mod_Q_Hab2/TEMP_VP/VP_A.log 2&gt;&amp;1
python3 VP_geta.py --tr datasets/processed/model_fitting/Mod_Q_Hab3/TEMP_VP/VP_Tr.feather --x datasets/processed/model_fitting/Mod_Q_Hab3/TEMP_VP/VP_X.feather --gamma datasets/processed/model_fitting/Mod_Q_Hab3/TEMP_VP/VP_Gamma.feather --output datasets/processed/model_fitting/Mod_Q_Hab3/TEMP_VP/VP_A.feather --ncores 3 --chunk_size 50 &gt;&gt; datasets/processed/model_fitting/Mod_Q_Hab3/TEMP_VP/VP_A.log 2&gt;&amp;1
python3 VP_geta.py --tr datasets/processed/model_fitting/Mod_Q_Hab4a/TEMP_VP/VP_Tr.feather --x datasets/processed/model_fitting/Mod_Q_Hab4a/TEMP_VP/VP_X.feather --gamma datasets/processed/model_fitting/Mod_Q_Hab4a/TEMP_VP/VP_Gamma.feather --output datasets/processed/model_fitting/Mod_Q_Hab4a/TEMP_VP/VP_A.feather --ncores 3 --chunk_size 50 &gt;&gt; datasets/processed/model_fitting/Mod_Q_Hab4a/TEMP_VP/VP_A.log 2&gt;&amp;1
python3 VP_geta.py --tr datasets/processed/model_fitting/Mod_Q_Hab4b/TEMP_VP/VP_Tr.feather --x datasets/processed/model_fitting/Mod_Q_Hab4b/TEMP_VP/VP_X.feather --gamma datasets/processed/model_fitting/Mod_Q_Hab4b/TEMP_VP/VP_Gamma.feather --output datasets/processed/model_fitting/Mod_Q_Hab4b/TEMP_VP/VP_A.feather --ncores 3 --chunk_size 50 &gt;&gt; datasets/processed/model_fitting/Mod_Q_Hab4b/TEMP_VP/VP_A.log 2&gt;&amp;1
python3 VP_geta.py --tr datasets/processed/model_fitting/Mod_Q_Hab10/TEMP_VP/VP_Tr.feather --x datasets/processed/model_fitting/Mod_Q_Hab10/TEMP_VP/VP_X.feather --gamma datasets/processed/model_fitting/Mod_Q_Hab10/TEMP_VP/VP_Gamma.feather --output datasets/processed/model_fitting/Mod_Q_Hab10/TEMP_VP/VP_A.feather --ncores 3 --chunk_size 50 &gt;&gt; datasets/processed/model_fitting/Mod_Q_Hab10/TEMP_VP/VP_A.log 2&gt;&amp;1
python3 VP_geta.py --tr datasets/processed/model_fitting/Mod_Q_Hab12a/TEMP_VP/VP_Tr.feather --x datasets/processed/model_fitting/Mod_Q_Hab12a/TEMP_VP/VP_X.feather --gamma datasets/processed/model_fitting/Mod_Q_Hab12a/TEMP_VP/VP_Gamma.feather --output datasets/processed/model_fitting/Mod_Q_Hab12a/TEMP_VP/VP_A.feather --ncores 3 --chunk_size 50 &gt;&gt; datasets/processed/model_fitting/Mod_Q_Hab12a/TEMP_VP/VP_A.log 2&gt;&amp;1
python3 VP_geta.py --tr datasets/processed/model_fitting/Mod_Q_Hab12b/TEMP_VP/VP_Tr.feather --x datasets/processed/model_fitting/Mod_Q_Hab12b/TEMP_VP/VP_X.feather --gamma datasets/processed/model_fitting/Mod_Q_Hab12b/TEMP_VP/VP_Gamma.feather --output datasets/processed/model_fitting/Mod_Q_Hab12b/TEMP_VP/VP_A.feather --ncores 3 --chunk_size 50 &gt;&gt; datasets/processed/model_fitting/Mod_Q_Hab12b/TEMP_VP/VP_A.log 2&gt;&amp;1
python3 VP_getf.py --x datasets/processed/model_fitting/Mod_Q_Hab1/TEMP_VP/VP_X.feather --beta_dir datasets/processed/model_fitting/Mod_Q_Hab1/TEMP_VP --output datasets/processed/model_fitting/Mod_Q_Hab1/TEMP_VP/VP_F.feather --ncores 3 &gt;&gt; datasets/processed/model_fitting/Mod_Q_Hab1/TEMP_VP/VP_F.log 2&gt;&amp;1
python3 VP_getf.py --x datasets/processed/model_fitting/Mod_Q_Hab2/TEMP_VP/VP_X.feather --beta_dir datasets/processed/model_fitting/Mod_Q_Hab2/TEMP_VP --output datasets/processed/model_fitting/Mod_Q_Hab2/TEMP_VP/VP_F.feather --ncores 3 &gt;&gt; datasets/processed/model_fitting/Mod_Q_Hab2/TEMP_VP/VP_F.log 2&gt;&amp;1
python3 VP_getf.py --x datasets/processed/model_fitting/Mod_Q_Hab3/TEMP_VP/VP_X.feather --beta_dir datasets/processed/model_fitting/Mod_Q_Hab3/TEMP_VP --output datasets/processed/model_fitting/Mod_Q_Hab3/TEMP_VP/VP_F.feather --ncores 3 &gt;&gt; datasets/processed/model_fitting/Mod_Q_Hab3/TEMP_VP/VP_F.log 2&gt;&amp;1
python3 VP_getf.py --x datasets/processed/model_fitting/Mod_Q_Hab4a/TEMP_VP/VP_X.feather --beta_dir datasets/processed/model_fitting/Mod_Q_Hab4a/TEMP_VP --output datasets/processed/model_fitting/Mod_Q_Hab4a/TEMP_VP/VP_F.feather --ncores 3 &gt;&gt; datasets/processed/model_fitting/Mod_Q_Hab4a/TEMP_VP/VP_F.log 2&gt;&amp;1
python3 VP_getf.py --x datasets/processed/model_fitting/Mod_Q_Hab4b/TEMP_VP/VP_X.feather --beta_dir datasets/processed/model_fitting/Mod_Q_Hab4b/TEMP_VP --output datasets/processed/model_fitting/Mod_Q_Hab4b/TEMP_VP/VP_F.feather --ncores 3 &gt;&gt; datasets/processed/model_fitting/Mod_Q_Hab4b/TEMP_VP/VP_F.log 2&gt;&amp;1
python3 VP_getf.py --x datasets/processed/model_fitting/Mod_Q_Hab10/TEMP_VP/VP_X.feather --beta_dir datasets/processed/model_fitting/Mod_Q_Hab10/TEMP_VP --output datasets/processed/model_fitting/Mod_Q_Hab10/TEMP_VP/VP_F.feather --ncores 3 &gt;&gt; datasets/processed/model_fitting/Mod_Q_Hab10/TEMP_VP/VP_F.log 2&gt;&amp;1
python3 VP_getf.py --x datasets/processed/model_fitting/Mod_Q_Hab12a/TEMP_VP/VP_X.feather --beta_dir datasets/processed/model_fitting/Mod_Q_Hab12a/TEMP_VP --output datasets/processed/model_fitting/Mod_Q_Hab12a/TEMP_VP/VP_F.feather --ncores 3 &gt;&gt; datasets/processed/model_fitting/Mod_Q_Hab12a/TEMP_VP/VP_F.log 2&gt;&amp;1
python3 VP_getf.py --x datasets/processed/model_fitting/Mod_Q_Hab12b/TEMP_VP/VP_X.feather --beta_dir datasets/processed/model_fitting/Mod_Q_Hab12b/TEMP_VP --output datasets/processed/model_fitting/Mod_Q_Hab12b/TEMP_VP/VP_F.feather --ncores 3 &gt;&gt; datasets/processed/model_fitting/Mod_Q_Hab12b/TEMP_VP/VP_F.log 2&gt;&amp;1</code></pre>
</div>
<p><br></p>
<button onclick="toggleScript('scriptContentNS6')" class="ShortBlockButton">
»» Example VP_SLURM.slurm file
</button>
<div id="scriptContentNS6" class="ShortBlock" style="display: none;">
<pre><code class="bash">#!/bin/bash
#SBATCH --job-name=VP_TF
#SBATCH --ntasks=1
#SBATCH --ntasks-per-node=1
#SBATCH --account=project_465001588
#SBATCH --cpus-per-task=1
#SBATCH --gpus-per-node=1
#SBATCH --time=01:30:00
#SBATCH --partition=small-g
#SBATCH --output=datasets/processed/model_fitting/TF_postprocess/log/%x-%A-%a.out
#SBATCH --error=datasets/processed/model_fitting/TF_postprocess/log/%x-%A-%a.out
#SBATCH --array=1-24

# File containing commands to be executed
File=datasets/processed/model_fitting/VP_Commands.txt

# Load TensorFlow module and configure environment
ml use /appl/local/csc/modulefiles
ml tensorflow
export TF_CPP_MIN_LOG_LEVEL=3
export TF_ENABLE_ONEDNN_OPTS=0

# Verify GPU availability
python3 -c "import tensorflow as tf; print(\"Num GPUs Available:\", len(tf.config.list_physical_devices(\"GPU\")))"

# Run array job
head -n $SLURM_ARRAY_TASK_ID $File | tail -n 1 | bash

echo End of program at `date`</code></pre>
</div>
<hr class="hr1">
</div>
</div>
<div class="section level2">
<h2 id="step-2-gpu">Step 2: GPU<a class="anchor" aria-label="anchor" href="#step-2-gpu"></a>
</h2>
<p>Latent factor predictions and variance partitioning are computed on
GPUs. Batch jobs can be submitted using the <code>sbatch</code>
command:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="ex">sbatch</span> datasets/processed/model_fitting/TF_postprocess/VP_SLURM.slurm</span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a><span class="ex">sbatch</span> datasets/processed/model_fitting/TF_postprocess/LF_SLURM.slurm</span></code></pre></div>
<p>Cross-validated models are fitted by submitting corresponding SLURM
commands (<em>in preparation</em>):</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a><span class="bu">source</span> datasets/processed/model_fitting/HabX/Model_Fitting_CV/CV_Bash_Fit.slurm</span></code></pre></div>
<hr class="hr1">
</div>
<div class="section level2">
<h2 id="step-3-cpu">Step 3: CPU<a class="anchor" aria-label="anchor" href="#step-3-cpu"></a>
</h2>
<p>The <code><a href="../reference/Mod_postprocessing.html">mod_postprocess_2_CPU()</a></code> function advances the
post-processing pipeline for HMSC models on the CPU, automating the
following tasks:</p>
<table class="table table table-condensed table-hover" style="font-size: 16px; margin-left: auto; margin-right: auto;"><tbody>
<tr>
<td style="text-align:left;padding-left: 2em;white-space: nowrap;" indentlevel="1">
<cc><code><a href="../reference/Response_curves.html">resp_curv_prepare_data()</a></code>,<br><code><a href="../reference/Response_curves.html">resp_curv_plot_SR()</a></code>,<br><code><a href="../reference/Response_curves.html">resp_curv_plot_species()</a></code>,<br><code><a href="../reference/Response_curves.html">resp_curv_plot_species_all()</a></code></cc><tab0></tab0>
</td>
<td style="text-align:left;">
continue processing and visualizing response curves
</td>
</tr>
<tr>
<td style="text-align:left;padding-left: 2em;white-space: nowrap;" indentlevel="1">
<cc><code><a href="../reference/Predict_Maps.html">predict_maps()</a></code></cc><tab0></tab0>
</td>
<td style="text-align:left;">
predict habitat suitability across climate scenarios, compute model
explanatory power (internal evaluation), and prepare maps for the Shiny
app
</td>
</tr>
<tr>
<td style="text-align:left;padding-left: 2em;white-space: nowrap;" indentlevel="1">
<cc><code><a href="../reference/plot_prediction.html">plot_prediction()</a></code></cc><tab0></tab0>
</td>
<td style="text-align:left;">
visualize species and species richness predictions as JPEG images
</td>
</tr>
<tr>
<td style="text-align:left;padding-left: 2em;white-space: nowrap;" indentlevel="1">
<cc><code><a href="../reference/plot_latent_factor.html">plot_latent_factor()</a></code></cc><tab0></tab0>
</td>
<td style="text-align:left;">
visualize spatial variation in site loadings of HMSC models as JPEG
images
</td>
</tr>
<tr>
<td style="text-align:left;padding-left: 2em;white-space: nowrap;" indentlevel="1">
<cc><code><a href="../reference/Variance_partitioning.html">variance_partitioning_compute()</a></code>,<br><code><a href="../reference/Variance_partitioning.html">variance_partitioning_plot()</a></code></cc><tab0></tab0>
</td>
<td style="text-align:left;">
continue processing and visualize variance partitioning
</td>
</tr>
<tr>
<td style="text-align:left;padding-left: 2em;white-space: nowrap;" indentlevel="1">
<cc><code><a href="../reference/plot_evaluation.html">plot_evaluation()</a></code></cc><tab0></tab0>
</td>
<td style="text-align:left;">
visualize explanatory power (internal model evaluation)
</td>
</tr>
<tr>
<td style="text-align:left;padding-left: 2em;white-space: nowrap;" indentlevel="1">
<cc><em>In preparation…</em></cc><tab0></tab0>
</td>
<td style="text-align:left;">
initiate post-processing of fitted cross-validated models and prepare
GPU commands for latent factor predictions
</td>
</tr>
</tbody></table>
<hr class="hr1">
</div>
<div class="section level2">
<h2 id="step-4-gpu">Step 4: GPU<a class="anchor" aria-label="anchor" href="#step-4-gpu"></a>
</h2>
<p>Predicting latent factors for cross-validated models on GPUs (<em>in
preparation</em>).</p>
<hr class="hr1">
</div>
<div class="section level2">
<h2 id="step-5-cpu">Step 5: CPU<a class="anchor" aria-label="anchor" href="#step-5-cpu"></a>
</h2>
<p>Evaluating the performance of cross-validated models (<em>in
preparation</em>).</p>
<hr class="hr1">
<p><span style="font-size: 1.2em; line-height: 0.8;"> <b>Previous
articles:</b><br><tab>↠<tab><a href="workflow_1_overview.html" class="ll">1.
Overview</a><br><tab>↠<tab><a href="workflow_2_abiotic_data.html" class="ll">2.
Processing abiotic data</a><br><tab>↠<tab><a href="workflow_3_biotic_data.html" class="ll">3.
Processing biotic data</a><br><tab>↠<tab><a href="workflow_4_model_fitting.html" class="ll">4. Model
fitting</a><br></tab></tab></tab></tab></tab></tab></tab></tab></span></p>
</div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p>Developed by <a href="https://elgabbas.netlify.app/" class="external-link">Ahmed El-Gabbas</a>.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.1.</p>
</div>

    </footer>
</div>





  </body>
</html>
