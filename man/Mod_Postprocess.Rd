% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/Mod_Postprocess.R
\name{Mod_Postprocess}
\alias{Mod_Postprocess}
\title{Model pipeline for Hmsc analysis}
\usage{
Mod_Postprocess(
  ModelDir = NULL,
  Hab_Abb = NULL,
  NCores = 8L,
  FromHPC = TRUE,
  EnvFile = ".env",
  Path_Hmsc = NULL,
  MemPerCpu = NULL,
  Time = NULL,
  FromJSON = FALSE,
  GPP_Dist = NULL,
  Tree = "Tree",
  Samples = 1000L,
  Thin = NULL,
  N_Grid = 50L,
  NOmega = 1000L,
  UseTF = TRUE,
  TF_Environ = NULL,
  TF_use_single = FALSE,
  LF_NCores = NCores,
  LF_Check = FALSE,
  LF_Temp_Cleanup = TRUE,
  Temp_Cleanup = TRUE,
  CC_Models = c("GFDL-ESM4", "IPSL-CM6A-LR", "MPI-ESM1-2-HR", "MRI-ESM2-0",
    "UKESM1-0-LL"),
  CC_Scenario = c("ssp126", "ssp370", "ssp585"),
  Pred_Clamp = TRUE,
  Fix_Efforts = "q90",
  Fix_Rivers = "q90",
  Pred_NewSites = TRUE,
  CVName = c("CV_Dist", "CV_Large")
)
}
\arguments{
\item{ModelDir}{String. Path to the root directory of the fitted models
without the trailing slash. Two folders will be created \code{Model_Fitted} and
\code{Model_Coda} to store merged model and coda objects, respectively.}

\item{Hab_Abb}{Character. Habitat abbreviation indicating the specific
\href{https://www.preslia.cz/article/pdf?id=11548}{SynHab} habitat type for
which data will be prepared. Valid values are \code{0}, \code{1}, \code{2}, \code{3}, \verb{4a},
\verb{4b}, \code{10}, \verb{12a}, \verb{12b}. For more details, see \href{https://doi.org/10.23855/preslia.2022.447}{Pysek et al.}.}

\item{NCores}{Integer specifying the number of parallel cores for
parallelization. Default: 8 cores.}

\item{FromHPC}{Logical indicating whether the work is being done from HPC, to
adjust file paths accordingly. Default: \code{TRUE}.}

\item{EnvFile}{Character. Path to the environment file containing paths to
data sources. Defaults to \code{.env}.}

\item{Path_Hmsc}{String. Path for the Hmsc-HPC.}

\item{MemPerCpu}{String. Memory per CPU allocation for the SLURM job.
Example: \verb{32G} for 32 gigabytes. Defaults to \code{NULL}. If not provided, the
function will throw an error.}

\item{Time}{String. Duration for which the job should run. Example:
\code{01:00:00} for one hour. If not provided, the function will throw an error.}

\item{FromJSON}{Logical. Indicates whether to convert loaded models from JSON
format before reading. Defaults to \code{FALSE}.}

\item{GPP_Dist}{Integer specifying the distance in \emph{kilometers} between knots
for GPP models.}

\item{Tree}{Character string specifying if phylogenetic tree was used in the
model. Valid values are "Tree" or "NoTree". Default is "Tree".}

\item{Samples}{Integer specifying the value for the number of MCMC samples in
the selected model. Defaults to 1000.}

\item{Thin}{Integer specifying the value for thinning in the selected model.}

\item{N_Grid}{Integer specifying the number of points along the gradient for
continuous focal variables. Defaults to 50. See \link[Hmsc:constructGradient]{Hmsc::constructGradient}
for more details.}

\item{NOmega}{An integer specifying the number of species to be sampled for
the \code{Omega} parameter transformation. Defaults to 100.}

\item{UseTF}{Logical indicating whether to use TensorFlow for calculations.
Defaults to TRUE.}

\item{TF_Environ}{Character string specifying the path to the Python
environment. Defaults to NULL. This argument is required if \code{UseTF} is
TRUE.}

\item{TF_use_single}{Logical indicating whether to use single precision for
the TF calculations. Defaults to \code{FALSE}.}

\item{LF_NCores}{Integer specifying the number of cores to use for parallel
processing. Defaults to 8.}

\item{LF_Check}{Logical. If TRUE, the function checks if the output files are
already created and valid. If FALSE, the function will only check if the
files exist without checking their integrity. Default is \code{FALSE}.}

\item{LF_Temp_Cleanup}{Logical indicating whether to delete temporary files
in the \code{Temp_Dir} after finishing the LF predictions.}

\item{Temp_Cleanup}{logical, indicating whether to clean up temporary files.
Defaults to \code{TRUE}.}

\item{CC_Models}{Character vector. Specifies the climate models for future
predictions. Default: \code{c("GFDL-ESM4", "IPSL-CM6A-LR", "MPI-ESM1-2-HR", "MRI-ESM2-0", "UKESM1-0-LL")}. Note: This parameter is temporary and may be
removed in future updates.}

\item{CC_Scenario}{Character vector. Specifies the climate scenarios for
future predictions. Default: \code{c("ssp126", "ssp370", "ssp585")}. Note: This
parameter is temporary and may be removed in future updates.}

\item{Pred_Clamp}{Logical indicating whether to clamp the sampling efforts at
a single value. Defaults to \code{TRUE}. If \code{TRUE}, the \code{Fix_Efforts} argument
must be provided.}

\item{Fix_Efforts}{Numeric or character. Defines the value to fix sampling
efforts less than the provided value. If numeric, the value is directly
used (log\if{html}{\out{<sub>}}10\if{html}{\out{</sub>}} scale). If character, it can be \code{median}, \code{mean},
\code{max}, or \code{q90} (q0\% Quantile). Using \code{max} can reflect extreme values
caused by rare, highly sampled locations (e.g., urban centers or popular
natural reserves). While using 90\% quantile avoid such extreme grid cells
while still capturing areas with high sampling effort. This argument is
mandatory when \code{Pred_Clamp} is set to \code{TRUE}.}

\item{Fix_Rivers}{Numeric or character. Similar to \code{Fix_Efforts}, but for
fixing the length of rivers. If numeric, the value is directly used
(log\if{html}{\out{<sub>}}10\if{html}{\out{</sub>}} scale). If character, it can be \code{median}, \code{mean}, \code{max},
\code{q90} (90\% quantile). It can be also \code{NULL} for not fixing the river length
predictor. Defaults to \code{q90}.}

\item{Pred_NewSites}{Logical indicating whether to predict habitat
suitability at new sites. Default: \code{TRUE}. Note: This parameter is
temporary and will be removed in future updates.}

\item{CVName}{Character vector specifying the name of the column(s) in the
model input data (see \link{Mod_PrepData} and \link{GetCV}) to be
used to cross-validate the models. The function allows the possibility of
using more than one way of assigning grid cells into cross-validation
folders. If multiple names are provided, separate cross-validation models
will be fitted for each column. Currently, there are three cross-validation
strategies, created using the \link{Mod_PrepData}: \code{CV_SAC}, \code{CV_Dist},
and \code{CV_Large} (see \link{GetCV}).}
}
\description{
This function sets up and runs an analysis pipeline for Hmsc models. It
includes steps for environment setup, loading packages, managing SLURM
refits, merging MCMC chains, convergence diagnostics, model summaries,
spatial predictions, response curve generation, and variance partitioning.
}
\author{
Ahmed El-Gabbas
}
