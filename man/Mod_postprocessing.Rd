% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/mod_postprocess.R, R/mod_postprocess_cv.R
\name{mod_postprocessing}
\alias{mod_postprocessing}
\alias{mod_postprocess_1_cpu}
\alias{mod_postprocessingS}
\alias{mod_prepare_tf}
\alias{mod_postprocess_2_cpu}
\alias{mod_postprocess_cv_1_cpu}
\alias{mod_postprocess_cv_2_cpu}
\title{Model pipeline for post-processing fitted Hmsc models}
\usage{
mod_postprocess_1_cpu(
  model_dir = NULL,
  hab_abb = NULL,
  strategy = "multisession",
  future_max_size = 1500L,
  n_cores = 8L,
  n_cores_pred = n_cores,
  n_cores_lf = n_cores,
  n_cores_vp = n_cores,
  env_file = ".env",
  path_hmsc = NULL,
  memory_per_cpu = "64G",
  job_runtime = "01:00:00",
  from_json = FALSE,
  gpp_dist = NULL,
  use_trees = "tree",
  mcmc_n_samples = 1000L,
  mcmc_thin = NULL,
  n_omega = 1000L,
  cv_name = c("cv_dist", "cv_large"),
  n_grid = 50L,
  use_tf = TRUE,
  tf_use_single = FALSE,
  lf_temp_cleanup = TRUE,
  lf_check = FALSE,
  temp_cleanup = TRUE,
  tf_environ = NULL,
  pred_new_sites = TRUE,
  width_omega = 26,
  height_omega = 22.5,
  width_beta = 25,
  height_beta = 35,
  spatial_model = TRUE,
  tar_predictions = TRUE,
  plot_predictions = TRUE,
  is_cv_model = FALSE,
  clamp_pred = TRUE,
  fix_efforts = "q90",
  fix_rivers = "q90",
  climate_models = c("GFDL-ESM4", "IPSL-CM6A-LR", "MPI-ESM1-2-HR", "MRI-ESM2-0",
    "UKESM1-0-LL"),
  climate_scenario = c("ssp126", "ssp370", "ssp585")
)

mod_prepare_tf(
  process_vp = TRUE,
  process_lf = TRUE,
  n_batch_files = 210L,
  env_file = ".env",
  working_directory = NULL,
  partition_name = "small-g",
  lf_runtime = "01:00:00",
  model_prefix = NULL,
  vp_runtime = "02:00:00"
)

mod_postprocess_2_cpu(
  model_dir = NULL,
  hab_abb = NULL,
  strategy = "multisession",
  future_max_size = 1500L,
  n_cores = 8L,
  n_cores_pred = n_cores,
  n_cores_lf = n_cores,
  n_cores_rc = n_cores,
  n_cores_vp = n_cores,
  env_file = ".env",
  gpp_dist = NULL,
  use_trees = "tree",
  mcmc_n_samples = 1000L,
  mcmc_thin = NULL,
  use_tf = TRUE,
  tf_environ = NULL,
  tf_use_single = FALSE,
  lf_check = FALSE,
  lf_temp_cleanup = TRUE,
  temp_cleanup = TRUE,
  n_grid = 50L,
  climate_models = c("GFDL-ESM4", "IPSL-CM6A-LR", "MPI-ESM1-2-HR", "MRI-ESM2-0",
    "UKESM1-0-LL"),
  climate_scenario = c("ssp126", "ssp370", "ssp585"),
  clamp_pred = TRUE,
  fix_efforts = "q90",
  fix_rivers = "q90",
  pred_new_sites = TRUE,
  tar_predictions = TRUE,
  rc_prepare = TRUE,
  rc_plot = TRUE,
  vp_prepare = TRUE,
  vp_plot = TRUE,
  predict_suitability = TRUE,
  plot_predictions = TRUE,
  plot_lf = TRUE,
  plot_internal_evaluation = TRUE,
  spatial_model = TRUE,
  is_cv_model = FALSE
)

mod_postprocess_cv_1_cpu(
  model_dir = NULL,
  cv_names = NULL,
  n_cores = 8L,
  strategy = "multisession",
  env_file = ".env",
  from_json = FALSE,
  use_tf = TRUE,
  tf_use_single = FALSE,
  tf_environ = NULL,
  n_cores_lf = n_cores,
  lf_only = TRUE,
  lf_temp_cleanup = TRUE,
  lf_check = FALSE,
  lf_runtime = "01:00:00",
  temp_cleanup = TRUE,
  n_batch_files = 210L,
  working_directory = NULL,
  partition_name = "small-g"
)

mod_postprocess_cv_2_cpu(
  model_dir = NULL,
  cv_names = NULL,
  n_cores = 8L,
  strategy = "multisession",
  env_file = ".env",
  use_tf = TRUE,
  tf_use_single = FALSE,
  temp_cleanup = TRUE,
  lf_temp_cleanup = TRUE,
  tf_environ = NULL,
  n_cores_lf = n_cores,
  lf_check = FALSE
)
}
\arguments{
\item{model_dir}{Character. Path to the root directory of the fitted model.}

\item{hab_abb}{Character. Habitat abbreviation indicating the specific
\href{https://www.preslia.cz/article/pdf?id=11548}{SynHab} habitat type. Valid
values: \code{0}, \code{1}, \code{2}, \code{3}, \verb{4a}, \verb{4b}, \code{10}, \verb{12a}, \verb{12b}. See \href{https://doi.org/10.23855/preslia.2022.447}{Pysek et al.} for details.}

\item{strategy}{Character. The parallel processing strategy to use. Valid
options are "sequential", "multisession" (default), "multicore", and
"cluster". See \code{\link[future:plan]{future::plan()}} and \code{\link[ecokit:set_parallel]{ecokit::set_parallel()}} for details.}

\item{future_max_size}{Numeric. Maximum allowed total size (in megabytes) of
global variables identified. See \code{future.globals.maxSize} argument of
\link[future:zzz-future.options]{future::future.options} for more details.}

\item{n_cores, n_cores_pred, n_cores_lf, n_cores_vp, n_cores_rc}{Integer. Number
of cores to use for parallel processing. They are used for different
processing steps: \code{n_cores} for merging chains and plotting convergence
convergence diagnostics; \code{n_cores_pred} for predicting species' habitat
suitability; \code{n_cores_lf} for predicting latent factors; \code{n_cores_vp} for
processing variance partitioning; and \code{n_cores_rc} for response curve
prediction. All default to \code{8L}. If \code{strategy = "sequential"}, all of these
arguments are set to \code{1L}.}

\item{env_file}{Character. Path to the environment file containing paths to
data sources. Defaults to \code{.env}.}

\item{path_hmsc}{Character. Path to the Hmsc-HPC installation.}

\item{memory_per_cpu}{Character. Memory allocation per CPU core. Example:
"32G" for 32 gigabytes. Defaults to "64G".}

\item{job_runtime}{Character. Maximum allowed runtime for jobs for refitting
the models (if needed) and cross validating models. Defaults to "01:00:00"
for one hour. If not provided, the function throws an error.}

\item{from_json}{Logical. Whether to convert loaded models from JSON format
before reading. Defaults to \code{FALSE}.}

\item{gpp_dist}{Integer. Distance in \emph{kilometres} between knots for the
selected model.}

\item{use_trees}{Character. Whether a phylogenetic tree was used in the
selected model. Accepts "tree" (default) or "no_tree".}

\item{mcmc_thin, mcmc_n_samples}{Integer. Thinning value and the number of
MCMC samples of the selected model.}

\item{n_omega}{Integer. The number of species to be sampled for the \code{Omega}
parameter transformation. Defaults to 100.}

\item{cv_name}{\code{NULL} or character vector. Column name(s) in the model input
data to be used to cross-validate the models (see \link{mod_prepare_data} and
\link{mod_cv_prepare}). If \code{cv_name = NULL}, no cross-validation data
preparation is done. See \link{mod_cv_fit} for valid options.}

\item{n_grid}{Integer. Number of points along the gradient for continuous
focal variables. Higher values result in smoother curves. Default: 50. See
\link[Hmsc:constructGradient]{Hmsc::constructGradient} for details.}

\item{use_tf}{Logical. Whether to use \code{TensorFlow} for calculations. Defaults
to \code{TRUE}.}

\item{tf_use_single}{Logical. Whether to use single precision for the
\code{TensorFlow} calculations. Defaults to \code{FALSE}.}

\item{lf_check}{Logical. If \code{TRUE}, the function checks if the output files
are already created and valid. If \code{FALSE}, the function will only check if
the files exist without checking their integrity. Default is \code{FALSE}.}

\item{temp_cleanup, lf_temp_cleanup}{Logical. Whether to delete temporary
files after finishing predicting latent factor or species distribution.
Default: \code{TRUE}.}

\item{tf_environ}{Character. Path to the Python environment. This argument is
required if \code{use_tf} is \code{TRUE} under Windows. Defaults to \code{NULL}.}

\item{pred_new_sites}{Logical. Whether to predict suitability at new sites.
Default: \code{TRUE}.}

\item{width_omega, height_omega, width_beta, height_beta}{Integer. The width and
height of the generated heatmaps of the Omega and Beta parameters in
centimetres.}

\item{spatial_model, plot_lf}{Logical. Whether the model is spatial (\code{TRUE})
or not (\code{FALSE}) and whether to plot latent factors for spatial models as
JPEG files (using \link{plot_latent_factor}). Defaults to \code{TRUE}.}

\item{is_cv_model}{Logical. Whether the model is a cross-validated model
(\code{TRUE}) or fitted with the full dataset (\code{FALSE}; default). If \code{TRUE}, the
explanatory and predictive power of the model will be computed.}

\item{clamp_pred}{Logical indicating whether to clamp the sampling efforts at
a single value. If \code{TRUE} (default), the \code{fix_efforts} argument must be
provided.}

\item{fix_efforts}{Numeric or character. When \code{clamp_pred = TRUE}, fixes the
sampling efforts predictor at this value during predictions. If numeric,
uses the value directly (on log\if{html}{\out{<sub>}}10\if{html}{\out{</sub>}} scale). If character, must be
one of \code{identity} (i.e., do not fix), \code{median}, \code{mean}, \code{max}, or \code{q90}
(90\% quantile). Using \code{max} may reflect extreme sampling efforts from
highly sampled locations, while \code{q90} captures high sampling areas without
extremes. Required if \code{clamp_pred = TRUE}.}

\item{fix_rivers}{Numeric, character, or \code{NULL}. Similar to \code{fix_efforts},
but for the river length predictor. If \code{NULL}, the river length is not
fixed. Default: \code{q90}.}

\item{climate_models}{Character vector. Climate models for future
predictions. Available options are \code{c("GFDL-ESM4", "IPSL-CM6A-LR", "MPI-ESM1-2-HR", "MRI-ESM2-0", "UKESM1-0-LL")} (default).}

\item{climate_scenario}{Character vector. Climate scenarios for future
predictions. Available options are: \code{c("ssp126", "ssp370", "ssp585")}
(default).}

\item{process_vp, process_lf}{Logical. Whether to prepares batch scripts for
variance partitioning computations and latent factor predictions on GPUs.
Defaults to \code{TRUE}.}

\item{n_batch_files}{Integer. Number of output batch files to create. Must be
less than or equal to the maximum job limit of the HPC environment.}

\item{working_directory}{Character. Optionally sets the working directory in
batch scripts to this path. If \code{NULL}, the directory remains unchanged.}

\item{partition_name}{Character. Name of the partition to submit the SLURM
jobs to. Default is \code{small-g}.}

\item{lf_runtime, vp_runtime}{Character. Time limit for latent factor
prediction and variance partitioning processing jobs, respectively.
Defaults are \code{01:00:00} and \code{02:00:00} respectively.}

\item{model_prefix}{Character. Prefix for the model name. A directory named
\code{model_prefix_TF} is created in the \code{model_dir} to store the \code{TensorFlow}
running commands. Defaults to \code{NULL}. This can not be \code{NULL}.}

\item{rc_prepare, rc_plot}{Logical. Whether to prepare the data for response
curve prediction (using \link{rc_prepare_data}) and plot the response curves as
JPEG files. (using \link{rc_plot_sr}, \link{rc_plot_species}, and
\link{rc_plot_species_all}). Defaults to \code{TRUE}.}

\item{vp_prepare, vp_plot}{Logical. Whether to prepare the data for variance
partitioning (using \link{variance_partitioning_compute}) and plot its results
(using \link{variance_partitioning_plot}). Defaults to \code{TRUE}.}

\item{predict_suitability, tar_predictions, plot_predictions}{Logical. Whether
to predict habitat suitability across different climate options (using
\link{predict_maps}), compress the resulted files into a single \verb{*.tar} file
(without compression), or to plot species and species richness predictions
as JPEG files (using \link{plot_prediction}). Defaults to \code{TRUE}.}

\item{plot_internal_evaluation}{Logical. Whether to compute and visualise
model internal evaluation (explanatory power) using \link{plot_evaluation}.
Defaults to \code{TRUE}.}

\item{cv_names}{Character vector. Names of cross-validation strategies to
merge, matching those used during model setup. Defaults to \code{c("cv_dist", "cv_large")}. The names should be one of \code{cv_dist}, \code{cv_large}, or
\code{cv_sac}. Applies only to \code{mod_merge_chains_cv}.}

\item{lf_only}{Logical. Whether to predict only the latent factor. This is
useful for distributing processing load between GPU and CPU. When \code{lf_only = TRUE}, latent factor prediction needs to be computed separately on GPU.
When computations are finished on GPU, the function can later be rerun with
\code{lf_only = FALSE} (default) to predict habitat suitability using the
already-computed latent factor predictions.}
}
\description{
These functions post-process fitted Hmsc models on both CPU and GPU. The main
functions in the pipeline includes \code{mod_postprocess_1_cpu}, \code{mod_prepare_tf},
and \code{mod_postprocess_2_cpu} for full models without cross-validation, as well
as \code{mod_postprocess_cv_1_cpu} and \code{mod_postprocess_cv_2_cpu} for
cross-validated models. See details for more information.
}
\details{
\strong{mod_postprocess_1_cpu}

This function performs the initial post-processing step for habitat-specific
fitted models, automating the following tasks:
\itemize{
\item check unsuccessful models: \link{mod_slurm_refit}
\item merge chains and save R objects (fitted model object and coda object) to
\code{qs2} or \code{RData} files: \link{mod_merge_chains}
\item visualise the convergence of all model variants fitted
\link{convergence_plot_all}
\item visualise the convergence of selected model, including plotting
Gelman-Rubin-Brooks \link{plot_gelman} and \link{convergence_plot} for model
convergence diagnostics of the \code{rho}, \code{alpha}, \code{omega}, and \code{beta}
parameters.
\item extract and save model summary: \link{mod_summary}
\item plotting model parameters: \link{mod_heatmap_omega}, \link{mod_heatmap_beta}
\item prepare data for cross-validation and fit initial cross-validated models:
\link{mod_cv_fit}
\item Prepare scripts for GPU processing, including:
\itemize{
\item predicting latent factors of the response curves:
\link{rc_prepare_data}
\item predicting latent factors for new sampling units: \link{predict_maps}
\item computing variance partitioning: \link{variance_partitioning_compute}
}
}\if{html}{\out{
<br/>
}}


\strong{mod_prepare_tf}

After running \code{mod_postprocess_1_cpu} for all habitat types, this function
prepares batch scripts for GPU computations of all habitat types:
\itemize{
\item for \if{html}{\out{<u>}}variance partitioning\if{html}{\out{</u>}}, the function matches all files with
the pattern \code{ "vp_.+command.txt"} (created by \link{variance_partitioning_compute}
and merges their contents into a single file
(\code{model_prefix_TF/vp_commands.txt}). Then, it prepares a SLURM script for
variance partitioning computations (\code{model_prefix_TF/vp_slurm.slurm}).
\item for \if{html}{\out{<u>}}latent factor predictions\if{html}{\out{</u>}}, the function matches all files
with the pattern \code{"^lf_new_sites_commands_.+.txt|^lf_rc_commands_.+txt"} and
split their contents into multiple scripts at the \code{model_prefix_TF} directory
for processing as a batch job. The function prepares a SLURM script for
latent factor predictions (\code{lf_slurm.slurm}).
}

This function is tailored for the LUMI HPC environment and assumes that the
\code{tensorflow} module is installed and correctly configured with all required
Python packages. On other HPC systems, users may need to modify the function
to load a Python virtual environment or install the required dependencies for
\code{TensorFlow} and related packages.

\if{html}{\out{<br/>}}\if{html}{\out{<br/>}}

\strong{mod_postprocess_2_cpu}

This function continues running the analysis pipeline for post-processing
Hmsc by automating the following steps:
\itemize{
\item process and visualise response curves: \link{response_curves}
\item predict habitat suitability across different climate options:
\link{predict_maps}
\item plot species & SR predictions as JPEG: \link{plot_prediction}
\item plot latent factors as JPEG: \link{plot_latent_factor}
\item process and visualise variance partitioning:
\link{variance_partitioning_compute} and \link{variance_partitioning_plot}
\item compute and visualizing model internal evaluation (explanatory power):
\link{plot_evaluation}
\item initiate post-processing of fitted cross-validated models: prepare
commands for latent factor predictions on GPU --- \strong{Ongoing}
}

This function should be run after:
\itemize{
\item completing \code{mod_postprocess_1_cpu} and \code{mod_prepare_tf} on CPU,
\item running \code{vp_slurm.slurm} and \code{lf_slurm.slurm} on GPU to process response
curves and latent factor predictions (both scripts are generated by
\code{mod_prepare_tf}).
\item submitting SLURM jobs for cross-validated model fitting.
}\if{html}{\out{
<br/>
}}


\strong{mod_postprocess_cv_1_cpu}

This function is similar to \code{mod_postprocess_1_cpu}, but it is specifically
designed for cross-validated models. It automates merging fitted
cross-validated model chains into \code{Hmsc} model objects and prepare scripts
for latent factor prediction on \code{TensorFlow} using \link{predict_maps_cv}.

\if{html}{\out{<br/>}}\if{html}{\out{<br/>}}

\strong{mod_postprocess_cv_2_cpu}

The function 1) processes \verb{*.feather} files resulted from Latent Factor
predictions (using \code{TensorFlow}) and saves LF predication to disk; 2)
predicts species-specific mean habitat suitability at testing
cross-validation folds and calculates testing evaluation metrics; 3)
generates plots of the evaluation metrics.
}
\author{
Ahmed El-Gabbas
}
