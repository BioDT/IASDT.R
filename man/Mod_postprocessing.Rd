% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/Mod_Postprocess.R
\name{Mod_postprocessing}
\alias{Mod_postprocessing}
\alias{Mod_Postprocess_1_CPU}
\alias{Mod_Prep_TF}
\alias{Mod_Postprocess_2_CPU}
\title{Model pipeline for post-processing fitted Hmsc models}
\usage{
Mod_Postprocess_1_CPU(
  ModelDir = NULL,
  Hab_Abb = NULL,
  NCores = 8L,
  FromHPC = TRUE,
  EnvFile = ".env",
  Path_Hmsc = NULL,
  MemPerCpu = NULL,
  Time = NULL,
  FromJSON = FALSE,
  GPP_Dist = NULL,
  Tree = "Tree",
  Samples = 1000L,
  Thin = NULL,
  NOmega = 1000L,
  CVName = c("CV_Dist", "CV_Large"),
  N_Grid = 50L,
  UseTF = TRUE,
  TF_use_single = FALSE,
  LF_NCores = NCores,
  LF_Temp_Cleanup = TRUE,
  LF_Check = FALSE,
  Temp_Cleanup = TRUE,
  TF_Environ = NULL,
  Pred_Clamp = TRUE,
  Fix_Efforts = "q90",
  Fix_Rivers = "q90",
  Pred_NewSites = TRUE,
  NCores_VP = 3,
  PlotWidth_Omega = 26,
  PlotHeight_Omega = 22.5,
  PlotWidth_Beta = 25,
  PlotHeight_Beta = 35
)

Mod_Prep_TF(
  Path_Models = "datasets/processed/model_fitting",
  NumFiles = 210L,
  EnvFile = ".env",
  WD = NULL,
  Partition_Name = "small-g",
  LF_Time = "01:00:00",
  VP_Time = "01:30:00"
)

Mod_Postprocess_2_CPU(
  ModelDir = NULL,
  Hab_Abb = NULL,
  NCores = 8L,
  FromHPC = TRUE,
  EnvFile = ".env",
  GPP_Dist = NULL,
  Tree = "Tree",
  Samples = 1000L,
  Thin = NULL,
  UseTF = TRUE,
  TF_Environ = NULL,
  TF_use_single = FALSE,
  LF_NCores = NCores,
  LF_Check = FALSE,
  LF_Temp_Cleanup = TRUE,
  Temp_Cleanup = TRUE,
  N_Grid = 50L,
  CC_Models = c("GFDL-ESM4", "IPSL-CM6A-LR", "MPI-ESM1-2-HR", "MRI-ESM2-0",
    "UKESM1-0-LL"),
  CC_Scenario = c("ssp126", "ssp370", "ssp585"),
  RC_NCores = 8L,
  Pred_Clamp = TRUE,
  Fix_Efforts = "q90",
  Fix_Rivers = "q90",
  Pred_NewSites = TRUE
)
}
\arguments{
\item{ModelDir}{Character. Path to the root directory of the fitted models.
Two folders will be created \code{Model_Fitted} and \code{Model_Coda} to store merged
model and coda objects, respectively.}

\item{Hab_Abb}{Character. Habitat abbreviation indicating the specific
\href{https://www.preslia.cz/article/pdf?id=11548}{SynHab} habitat type for
which data will be prepared. Valid values are \code{0}, \code{1}, \code{2}, \code{3}, \verb{4a},
\verb{4b}, \code{10}, \verb{12a}, \verb{12b}. For more details, see \href{https://doi.org/10.23855/preslia.2022.447}{Pysek et al.}.}

\item{NCores}{Integer. Number of CPU cores to use for parallel processing.
Default: 8.}

\item{FromHPC}{Logical. Whether the processing is being done on an
High-Performance Computing (HPC) environment, to adjust file paths
accordingly. Default: \code{TRUE}.}

\item{EnvFile}{Character. Path to the environment file containing paths to
data sources. Defaults to \code{.env}.}

\item{Path_Hmsc}{Character. Path to the Hmsc-HPC installation.}

\item{MemPerCpu}{Character. Memory allocation per CPU core. Example: "32G"
for 32 gigabytes. Required --- if not provided, the function throws an
error.}

\item{Time}{Character. Maximum allowed runtime for the job. Example:
"01:00:00" for one hour. Required --- if not provided, the function throws
an error.}

\item{FromJSON}{Logical. Whether to convert loaded models from JSON
format before reading. Defaults to \code{FALSE}.}

\item{GPP_Dist}{Integer. Distance in \emph{kilometers} between knots for the
selected model.}

\item{Tree}{Character. Whether a phylogenetic tree was used in the selected
model. Accepts "Tree" (default) or "NoTree".}

\item{Thin, Samples}{Integer. Thinning value and the number of MCMC samples of
the selected model.}

\item{NOmega}{Integer. The number of species to be sampled for
the \code{Omega} parameter transformation. Defaults to 100.}

\item{CVName}{Character vector. Column name(s) in the model input data to be
used to cross-validate the models (see \link{Mod_PrepData} and \link{Mod_GetCV}).
The function allows the possibility of using more than one way of
assigning grid cells into cross-validation folders. If multiple names are
provided, separate cross-validation models will be fitted for each
cross-validation type. Currently, there are three cross-validation
strategies: \code{CV_SAC}, \code{CV_Dist}, and \code{CV_Large}. Defaults to \code{c("CV_Dist", "CV_Large")}.}

\item{N_Grid}{Integer. Number of points along the gradient for continuous
focal variables. Higher values result in smoother curves. Default: 50. See
\link[Hmsc:constructGradient]{Hmsc::constructGradient} for details.}

\item{UseTF}{Logical. Whether to use TensorFlow for calculations. Defaults to
\code{TRUE}.}

\item{TF_use_single}{Logical. Whether to use single precision for the
TensorFlow calculations. Defaults to \code{FALSE}.}

\item{LF_NCores}{Integer. Number of cores to use for parallel processing of
latent factor prediction. Defaults to 8L.}

\item{LF_Temp_Cleanup}{Logical. Whether to delete temporary files in the
\code{Temp_Dir} directory after finishing the LF predictions.}

\item{LF_Check}{Logical. If \code{TRUE}, the function checks if the output files
are already created and valid. If \code{FALSE}, the function will only check if
the files exist without checking their integrity. Default is \code{FALSE}.}

\item{Temp_Cleanup}{Logical. Whether to clean up temporary files.
Defaults to \code{TRUE}.}

\item{TF_Environ}{Character. Path to the Python environment. This argument is
required if \code{UseTF} is \code{TRUE}.}

\item{Pred_Clamp}{Logical indicating whether to clamp the sampling efforts at
a single value. If \code{TRUE} (default), the \code{Fix_Efforts} argument must be
provided.}

\item{Fix_Efforts}{Numeric or character. If \code{Pred_Clamp = TRUE}, the sampling
efforts predictor with values U+02264 \code{Fix_Efforts} is fixed at
\code{Fix_Efforts} during predictions. If numeric, the value is directly used
(log\if{html}{\out{<sub>}}10\if{html}{\out{</sub>}} scale). If character, it can be one of \code{median}, \code{mean},
\code{max}, or \code{q90} (90\% Quantile). Using \code{max} can reflect extreme values
caused by rare, highly sampled locations (e.g., urban centers or popular
natural reserves). While using 90\% quantile avoid such extreme grid cells
while still capturing areas with high sampling effort. This argument is
mandatory when \code{Pred_Clamp} is set to \code{TRUE}.}

\item{Fix_Rivers}{Numeric or character. Similar to \code{Fix_Efforts}, but for
fixing the length of rivers. If numeric, the value is directly used
(log\if{html}{\out{<sub>}}10\if{html}{\out{</sub>}} scale). If character, it can be one of \code{median}, \code{mean},
\code{max}, \code{q90} (90\% quantile). It can be also \code{NULL} for not fixing the river
length predictor. Defaults to \code{q90}.}

\item{Pred_NewSites}{Logical. Whether to predict habitat suitability at new
sites. Default: \code{TRUE}. Note: This parameter is temporary and will be
removed in future updates.}

\item{NCores_VP}{Integer. Number of cores to use for variance partitioning.
Defaults to 3.}

\item{PlotWidth_Omega, PlotHeight_Omega, PlotWidth_Beta, PlotHeight_Beta}{Integer. The width and height of the generated heatmaps of the Omega and
Beta parameters in centimeters.}

\item{Path_Models}{Character. Directory for fitted models. Default is
\code{datasets/processed/model_fitting}. A subdirectory \code{TF_postprocess} will be
created to store the batch scripts and log files.}

\item{NumFiles}{Integer. Number of output batch files to create. Must be less
than or equal to the maximum job limit of the HPC environment.}

\item{WD}{Character. Optionally sets the working directory in batch scripts
to this path. If \code{NULL}, the directory remains unchanged.}

\item{Partition_Name}{Character. Name of the partition to submit the SLURM
jobs to. Default is \code{small-g}.}

\item{LF_Time, VP_Time}{Character. Time limit for latent factor prediction and
variance partitioning processing jobs, respectively. Default is \code{01:00:00}.}

\item{CC_Models}{Character vector. Climate models for future predictions.
Available options are \code{c("GFDL-ESM4", "IPSL-CM6A-LR", "MPI-ESM1-2-HR", "MRI-ESM2-0", "UKESM1-0-LL")} (default).}

\item{CC_Scenario}{Character vector. Climate scenarios for future
predictions. Available options are: \code{c("ssp126", "ssp370", "ssp585")}
(default).}

\item{RC_NCores}{Integer. The number of cores to use for response curve
prediction. Defaults to \code{8}.}
}
\description{
These functions post-process fitted Hmsc models on both CPU and GPU. The
pipeline is under active development and may change in future updates.
Currently, there are three main functions in this script:
\code{Mod_Postprocess_1_CPU()}, \code{Mod_Prep_TF()}, and \code{Mod_Postprocess_2_CPU()}.
See details for more information.
}
\details{
\strong{Mod_Postprocess_1_CPU}

This function performs the initial post-processing step for habitat-specific
fitted models, automating the following tasks:
\itemize{
\item check unsuccessful models: \link{Mod_SLURM_Refit}
\item merge chains and save R objects (fitted model object and coda object) to
\code{qs2} or \code{RData} files: \link{Mod_Merge_Chains}
\item visualize the convergence of all model variants fitted
\link{Convergence_Plot_All}
\item visualize the convergence of selected model, including plotting
Gelman-Rubin-Brooks \link{PlotGelman} and \link{Convergence_Plot} for model convergence
diagnostics of the \code{rho}, \code{alpha}, \code{omega}, and \code{beta} parameters.
\item extract and save model summary: \link{Mod_Summary}
\item plotting model parameters: \link{Mod_Heatmap_Omega}, \link{Mod_Heatmap_Beta}
\item prepare data for cross-validation and fit initial cross-validated models:
\link{Mod_CV_Fit}
\item Prepare scripts for GPU processing, including:
\itemize{
\item predicting latent factors of the response curves: \link{RespCurv_PrepData}
\item predicting latent factors for new sampling units: \link{Predict_Maps}
\item computing variance partitioning: \link{VarPar_Compute}
}
}\if{html}{\out{
<hr>
}}


\strong{Mod_Prep_TF}

After running \code{Mod_Postprocess_1_CPU} for all habitat types, this function
prepares batch scripts for GPU computations of all habitat types:
\itemize{
\item for \if{html}{\out{<u>}}variance partitioning\if{html}{\out{</u>}}, the function matches all files with
the pattern \code{ "VP_.+Command.txt"} (created by \link{VarPar_Compute} and merges
their contents into a single file (\code{TF_postprocess/VP_Commands.txt}). Then,
it prepares a SLURM script for variance partitioning computations
(\code{TF_postprocess/VP_SLURM.slurm}).
\item for \if{html}{\out{<u>}}latent factor predictions\if{html}{\out{</u>}}, the function matches all files
with the pattern \code{"^LF_NewSites_Commands_.+.txt|^LF_RC_Commands_.+txt"} and
split their contents into multiple scripts at the \code{TF_postprocess} directory
for processing as a batch job. The function prepares a SLURM script for
latent factor predictions (\code{LF_SLURM.slurm}).
}

This function is tailored for the LUMI HPC environment and assumes that the
\code{tensorflow} module is installed and correctly configured with all required
Python packages. On other HPC systems, users may need to modify the function
to load a Python virtual environment or install the required dependencies for
TensorFlow and related packages.\if{html}{\out{
<hr>
}}


\strong{Mod_Postprocess_2_CPU}

This function continues running the analysis pipeline for post-processing
Hmsc by automating the following steps:
\itemize{
\item process and visualize response curves: \link{Response_curves}
\item predict habitat suitability across different climate options:
\link{Predict_Maps}
\item plot species & SR predictions as JPEG: \link{Mod_Predict_Plot}
\item plot latent factors as JPEG: \link{Mod_Plot_LF}
\item process and visualize variance partitioning: \link{VarPar_Compute} and
\link{VarPar_Plot}
\item compute and visualizing model internal evaluation (explanatory power):
\link{Mod_Eval_Plot}
\item initiate post-processing of fitted cross-validated models: prepare
commands for latent factor predictions on GPU --- \strong{Ongoing}
}

This function should be run after:
\itemize{
\item completing \code{Mod_Postprocess_1_CPU} and \code{Mod_Prep_TF} on CPU,
\item running \code{VP_SLURM.slurm} and \code{LF_SLURM.slurm} on GPU to process response
curves and latent factor predictions (both scripts are generated by
\code{Mod_Prep_TF}).
\item submitting SLURM jobs for cross-validated model fitting.
}
}
\author{
Ahmed El-Gabbas
}
