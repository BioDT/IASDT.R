% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/mod_predict_latent_factor.R
\name{predict_latent_factor}
\alias{predict_latent_factor}
\title{Draws samples from the conditional predictive distribution of latent factors}
\usage{
predict_latent_factor(
  units_pred,
  units_model,
  post_eta,
  post_alpha,
  lf_rl,
  n_cores_lf = 8L,
  strategy = "multisession",
  temp_dir = "temp_pred",
  lf_temp_cleanup = TRUE,
  model_name = NULL,
  use_tf = TRUE,
  tf_environ = NULL,
  tf_use_single = FALSE,
  lf_out_file = NULL,
  lf_return = FALSE,
  lf_check = FALSE,
  lf_commands_only = FALSE,
  solve_max_attempts = 5L,
  solve_chunk_size = 50L,
  verbose = TRUE
)
}
\arguments{
\item{units_pred}{a factor vector with random level units for which
predictions are to be made}

\item{units_model}{a factor vector with random level units that are
conditioned on}

\item{post_eta}{Character. Path of \code{post_eta}; a list containing samples of
random factors at conditioned units}

\item{post_alpha}{a list containing samples of range (lengthscale) parameters
for latent factors}

\item{lf_rl}{a HmscRandomLevel-class object that describes the random level
structure}

\item{n_cores_lf}{Integer. Number of cores to use for parallel processing of
latent factor prediction. Defaults to 8L.}

\item{strategy}{Character. The parallel processing strategy to use. Valid
options are "sequential", "multisession" (default), "multicore", and
"cluster". See \code{\link[future:plan]{future::plan()}} and \code{\link[ecokit:set_parallel]{ecokit::set_parallel()}} for details.}

\item{temp_dir}{Character. Path for temporary storage of intermediate files.}

\item{lf_temp_cleanup}{Logical. Whether to delete temporary files in the
\code{temp_dir} directory after finishing the LF predictions.}

\item{model_name}{Character. Prefix for temporary file names. Defaults to
\code{NULL}, in which case no prefix is used.}

\item{use_tf}{Logical. Whether to use \code{TensorFlow} for calculations. Defaults
to \code{TRUE}.}

\item{tf_environ}{Character. Path to the Python environment. This argument is
required if \code{use_tf} is \code{TRUE} under Windows. Defaults to \code{NULL}.}

\item{tf_use_single}{Logical. Whether to use single precision for the
\code{TensorFlow} calculations. Defaults to \code{FALSE}.}

\item{lf_out_file}{Character. Path to save the outputs. If \code{NULL} (default),
the predicted latent factors are not saved to a file. This should end with
either \verb{*.qs2} or \verb{*.RData}.}

\item{lf_return}{Logical. Whether the output should be returned. Defaults to
\code{FALSE}. If \code{lf_out_file} is \code{NULL}, this parameter cannot be set to
\code{FALSE} because the function needs to return the result if it is not saved
to a file.}

\item{lf_check}{Logical. If \code{TRUE}, the function checks if the output files
are already created and valid. If \code{FALSE}, the function will only check if
the files exist without checking their integrity. Default is \code{FALSE}.}

\item{lf_commands_only}{Logical. If \code{TRUE}, returns the command to run the
Python script. Default is \code{FALSE}.}

\item{solve_max_attempts}{Integer. Maximum number of attempts to run solve
and crossprod internal function \link{run_crossprod_solve}. Default is 5L.}

\item{solve_chunk_size}{Integer. Chunk size for \code{solve_and_multiply} Python
function. Default is 50L.}

\item{verbose}{Logical. If \code{TRUE}, logs detailed information during
execution. Default is \code{TRUE}.}
}
\description{
This function is optimized for speed using parallel processing and optionally
\code{TensorFlow} for matrix operations. This function is adapted from
\link[Hmsc:predictLatentFactor]{Hmsc::predictLatentFactor} with equivalent results to the original function
when \code{predictMean = TRUE}.
}
\details{
The function is expected to be faster than the original function in
the \code{Hmsc} package, especially when using \code{TensorFlow} for calculations and
when working in parallel.

The main difference is that this function:
\itemize{
\item allow for parallel processing (\code{n_cores_lf} argument);
\item when \code{TensorFlow} is used (\code{use_tf = TRUE}), matrix
calculations are much faster, particularly when used on GPU. The following
Python modules are needed: \code{numpy}, \code{tensorflow}, \code{rdata}, \code{xarray}, and
\code{pandas}. To use \code{TensorFlow} under Windows, the argument \code{tf_environ}
should be set to the path of a Python environment with \code{TensorFlow}
installed;
\item if \code{use_tf} is set to \code{FALSE}, the function uses \code{R} (supported by
relatively faster \code{CPP} functions) in the calculations;
\item \code{d11} and \code{d12} matrices are processed only once and saved to disk and
called when needed.
}
}
\seealso{
\link[Hmsc:predictLatentFactor]{Hmsc::predictLatentFactor}
}
